[{"content":" Why I Needed Sequential Updates I maintain 20‚Äëplus ESPHome nodes on a small ARM‚Äëbased Home Assistant server. Each OTA update forces a full C++ compile, which can take ‚âà‚ÄØ5‚ÄØmin per device. Two compiles at once, however, balloon the total wall‚Äëtime (CPU contention + I/O) and can push the server to its limits.\nI opened esphome/feature‚Äërequests¬†#2171 asking for a shared build‚Äëcache across devices‚Äîbecause most of my YAML files differ only in pin mappings. If the cache wasn\u0026rsquo;t per device, maybe I could have kicked off all devices at once, or even used esphomes own \u0026ldquo;update all\u0026rdquo; as it had its own issues with not being able to run for hours and hours. Until that feature lands, the workaround has been to update devices strictly one after another.\nInitially I handled that in Node‚ÄëRED with a JavaScript function node. As Home Assistant‚Äôs script syntax supports loops, variables and conditional waits, I migrated everything to a HA‚Äënative script. Below you‚Äôll learn exactly how it works and why it‚Äôs much easier to maintain.\nTL;DR ‚Äì We gather every update.xxx_firmware entity that has an ESPHome update available, then loop through them with update.install, letting Home¬†Assistant block until each flash is done. All progress is pushed to a persistent notification so you can follow along.\nThe Building Blocks Home Assistant scripts have picked up several Jinja‚Äëpowered features over the last two years:\nBlock What it does variables: Define scoped values you can reuse later in the script. repeat: Iterate over a list \u0026amp; expose repeat.index / repeat.item. choose: Classic if / else logic. wait_template: Pause until a condition becomes true (so we can prevent two updates from running concurrently). We‚Äôll lean on variables + repeat to accomplish our sequential workflow.\nPicking the Devices The first step is to build a list of only those firmware entities that (a) belong to ESPHome and (b) actually have an update pending:\n- variables: esphome_updates: \u0026gt; {{ states.update | selectattr(\u0026#39;attributes.title\u0026#39;, \u0026#39;equalto\u0026#39;, \u0026#39;ESPHome\u0026#39;) | selectattr(\u0026#39;state\u0026#39;, \u0026#39;equalto\u0026#39;, \u0026#39;on\u0026#39;) | map(attribute=\u0026#39;entity_id\u0026#39;) | list }} The states.update gives you every update.* entity. Two chained selectattr() filters it down to only ESPHome devices that have updates, and map() grabs the entity IDs. We store the result in esphome_updates for use throughout the script.\nIf that list ends up empty we bail out early with a \u0026ldquo;Nothing to do\u0026rdquo; notification‚Äîno sense spamming the log.\nWaiting for Ongoing Flashes Before kicking off a batch I also make sure no other ESPHome update is already running‚Äîhandy if you sometimes flash a single node ad‚Äëhoc from the ESPHome UI.\n- wait_template: \u0026gt; {{ states.update | selectattr(\u0026#39;attributes.title\u0026#39;, \u0026#39;equalto\u0026#39;, \u0026#39;ESPHome\u0026#39;) | selectattr(\u0026#39;attributes.in_progress\u0026#39;, \u0026#39;equalto\u0026#39;, true) | list | length == 0 }} That tiny block protects you from overlapping runs. We could have used the mode: queued, but that doesn\u0026rsquo;t handle if the script was started, stopped and then started again.\nThe Loop Once we‚Äôre clear, we iterate one entity at a time. Inside the loop we set an easy‚Äëto‚Äëread variable and fire the installer:\n- repeat: for_each: \u0026#34;{{ esphome_updates }}\u0026#34; sequence: - variables: this_entity: \u0026#34;{{ repeat.item }}\u0026#34; - service: persistent_notification.create data: title: \u0026#34;ESPHome Update Started\u0026#34; message: \u0026gt; üîÑ Starting update for {{ this_entity }} ({{ repeat.index }} of {{ esphome_updates | count }}) notification_id: update_esphome_notification - service: update.install data: entity_id: \u0026#34;{{ this_entity }}\u0026#34; - service: persistent_notification.create data: title: \u0026#34;ESPHome Update Completed\u0026#34; message: \u0026#34;‚úÖ Finished updating {{ this_entity }}\u0026#34; notification_id: update_esphome_notification Highlights\nrepeat.index is 1‚Äëbased, perfect for quick X‚ÄØof‚ÄØY status lines. update.install now blocks until the firmware write finishes, so the second notification fires at the exact moment the node reboots. Full Script You can grab the script from this link. To install it, create a new script, edit it as yaml, and paste in this thing.\n‚ÑπÔ∏è Stick the script on a Script Button in Lovelace so you can kick off updates with one tap.\nHappy flashing!\n","permalink":"https://blog.mbwarez.dk/posts/2025/05/esphome-sequential-updates/","summary":"\u003chr\u003e\n\u003ch1 id=\"why-i-needed-sequential-updates\"\u003eWhy I Needed Sequential Updates\u003c/h1\u003e\n\u003cp\u003eI maintain \u003cstrong\u003e20‚Äëplus ESPHome nodes\u003c/strong\u003e on a small ARM‚Äëbased Home Assistant server. Each OTA update forces a \u003cem\u003efull\u003c/em\u003e C++ compile, which can take \u003cstrong\u003e‚âà‚ÄØ5‚ÄØmin\u003c/strong\u003e per device. Two compiles at once, however, balloon the total wall‚Äëtime (CPU contention + I/O) and can push the server to its limits.\u003c/p\u003e\n\u003cp\u003eI opened \u003ca href=\"https://github.com/esphome/feature-requests/issues/2171\"\u003eesphome/feature‚Äërequests¬†#2171\u003c/a\u003e asking for \u003cstrong\u003ea shared build‚Äëcache across devices\u003c/strong\u003e‚Äîbecause most of my YAML files differ only in pin mappings. If the cache wasn\u0026rsquo;t per device, maybe I could have kicked off all devices at once, or even used esphomes own \u0026ldquo;update all\u0026rdquo; as it had its own issues with not being able to run for hours and hours. Until that feature lands, the workaround has been to \u003cstrong\u003eupdate devices strictly one after another\u003c/strong\u003e.\u003c/p\u003e","title":"Updating ESPHome Devices Sequentially with Home¬†Assistant Scripts"},{"content":"Polling a sensor at a fixed interval ‚Äî say, every 5 minutes ‚Äî is simple to set up. But in practice, it can be wasteful or inadequate: polling too often wastes bandwidth and may hit rate limits, while polling too slowly can leave your data stale when you need it most.\nIdeally, we\u0026rsquo;d poll frequently when someone might be watching, and rarely (or not at all) when the house is asleep or empty. That means dynamic polling based on context.\nThis post shows how I built such a dynamic polling strategy for the Danish public transport integration, HAFAS, in Home Assistant. But the idea applies to any sensor with on-demand updates.\nNote: Home Assistant does have a Rejseplanen integration directly, but its defunct as Rejseplanen deprecated their v1 API. The HAFAS integration is alive and well.\nWhy Control Polling at All? Most Home Assistant integrations poll their data on a regular basis. The Rejseplanen integration is no exception ‚Äî it polls automatically unless you override it.\nBut instead of setting a global scan_interval, which would affect every entity in the integration, we can disable polling at the entity level via the UI and trigger updates ourselves.\nHere‚Äôs how to do that: üëâ Why use an automation instead of changing the integration\u0026rsquo;s polling configuration?\nBuilding a Custom Update Schedule This post presents one strategy. My choices reflect a typical workday:\nFrequent updates during morning and afternoon commutes Less frequent updates during the day Sparse updates in the evening or at night But you can adapt it to your routine: some may want more polling on weekends, or more updates in the evening.\nTo detect weekdays and holidays, I use Home Assistant‚Äôs Workday Sensor, which returns on during normal workdays and off on weekends or holidays. It‚Äôs great for this kind of logic.\nThe Automation: Smart Polling Make sure to disable automatic polling first (as described above). Then replace sensor.rejseplanen and binary_sensor.workday with your actual entity ID.\n# Example automation: Smart polling for train departures automation: - alias: timer/rejseplanen (smart schedule) description: Update train departures with smart frequency based on time and day. mode: single trigger: - platform: time_pattern minutes: \u0026#34;/1\u0026#34; condition: [] action: - choose: - alias: \u0026#34;[frequent] Weekday Morning Commute (06:30‚Äì08:30)\u0026#34; conditions: - condition: time after: \u0026#34;06:30:00\u0026#34; before: \u0026#34;08:30:00\u0026#34; - condition: state entity_id: binary_sensor.workday state: \u0026#34;on\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 2 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen - alias: \u0026#34;[off-peak] Weekday Midday (08:30‚Äì14:00)\u0026#34; conditions: - condition: time after: \u0026#34;08:30:00\u0026#34; before: \u0026#34;14:00:00\u0026#34; - condition: state entity_id: binary_sensor.workday state: \u0026#34;on\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 8 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen - alias: \u0026#34;[frequent] Weekday Afternoon Return (14:00‚Äì19:00)\u0026#34; conditions: - condition: time after: \u0026#34;14:00:00\u0026#34; before: \u0026#34;19:00:00\u0026#34; - condition: state entity_id: binary_sensor.workday state: \u0026#34;on\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 2 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen - alias: \u0026#34;[infrequent] Weekday Evening (19:00‚Äì22:00)\u0026#34; conditions: - condition: time after: \u0026#34;19:00:00\u0026#34; before: \u0026#34;22:00:00\u0026#34; - condition: state entity_id: binary_sensor.workday state: \u0026#34;on\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 15 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen - alias: \u0026#34;[off-peak] Weekend Daytime (08:00‚Äì22:00)\u0026#34; conditions: - condition: time after: \u0026#34;08:00:00\u0026#34; before: \u0026#34;22:00:00\u0026#34; - condition: state entity_id: binary_sensor.workday state: \u0026#34;off\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 8 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen - alias: \u0026#34;[infrequent] All Nights (22:00‚Äì06:30)\u0026#34; conditions: - condition: or conditions: - condition: time after: \u0026#34;22:00:00\u0026#34; - condition: time before: \u0026#34;06:30:00\u0026#34; - condition: template value_template: \u0026#34;{{ now().minute % 15 == 0 }}\u0026#34; sequence: - service: homeassistant.update_entity data: entity_id: sensor.rejseplanen Ideas for Further Improvement You can make this even smarter by reacting to presence:\nIs anyone home? Has someone opened the front door? Is there motion in the hallway ‚Äî near a dashboard or wall tablet? These conditions can be placed at the top of the choose: block so they take priority. That way, updates happen right when someone might be looking, regardless of the time.\nConclusion With this setup, your dashboards and displays will stay fresh when people care, and quiet down when they don‚Äôt.\nPerfect for hallway tablets, entryway info panels, or just for keeping the Rejseplanen API happy while saving bandwidth.\nWant even more control? Extend the logic with presence detection, calendar events, or anything else you can automate in Home Assistant.\n","permalink":"https://blog.mbwarez.dk/posts/2025/05/ha-smart-poll/","summary":"\u003cp\u003ePolling a sensor at a fixed interval ‚Äî say, every 5 minutes ‚Äî is simple to set up. But in practice, it can be wasteful or inadequate: polling too often wastes bandwidth and may hit rate limits, while polling too slowly can leave your data stale when you need it most.\u003c/p\u003e\n\u003cp\u003eIdeally, we\u0026rsquo;d \u003cstrong\u003epoll frequently when someone might be watching\u003c/strong\u003e, and \u003cstrong\u003erarely (or not at all)\u003c/strong\u003e when the house is asleep or empty. That means \u003cstrong\u003edynamic polling based on context\u003c/strong\u003e.\u003c/p\u003e","title":"Smart Refresh Schedule for Sensors in Home Assistant"},{"content":"Introduction I have a disk with bad blocks. The filesystem I\u0026rsquo;m using (such as ZFS) doesn\u0026rsquo;t support marking bad blocks like ext did, and completely replacing the disk is costly and unnecessary. Instead, I\u0026rsquo;ve used dmsetup to create a virtual disk that excludes the bad sectors, allowing the filesystem to work with the remaining good areas.\nThis guide covers the process of scanning the disk, preparing a custom partition, setting up dmsetup, and ensuring everything works across reboots. I\u0026rsquo;ve additionally included steps to ensure that the dmsetup configuration follows the disk, ensuring you don\u0026rsquo;t loose that critical piece of information.\n‚ÑπÔ∏è Info: If you\u0026rsquo;re mounting a disk that was prepared by this post, skip to step 4 and copy files from the ext3 filesystem in partition 1.\nEssential components Device mapper is a linux component that allows us to create virtual devices, who\u0026rsquo;s underlying implementation can change. This can be used to implement striping, multipathing, redirect parts of the device to different physical disks, various tests like artificial delays and errors and so on. In this post, I use it to map around bad blocks. Identifying disks by their id - to ensure that we never encounter issues due to disk renumbering, or when moving between systems, it is essential to use the disk ids instead of their temporary names. All disks should be available in /dev/disk/by-id/ on your linux system. My approach will use the disk id, like scsi-88774aaeef234 as the identifier for the device. ‚ÑπÔ∏è Info: You can replace DISK_ID in all the following text by putting it here: The process The process will:\nCreate a partition layout on the faulty disk Run badblocks to identify faulty areas Create the necessary dmsetup configuration and systemd unit \u0026ldquo;Mount\u0026rdquo; the virtual device, and ensure it mounts on boot 0. Identify the disk Say you want to operate on /dev/sdk. Identify its id, by looking in /dev/disk/by-id/, like this:\nfind /dev/disk/by-id -lname \u0026#34;*sdk\u0026#34; This above script will list all the links in by-id that point to sdk. Choose your preferred id, and substitue the DISK_ID in all future bits of this post with the name of that. As an example, you may choose /dev/disk/by-id/scsi-35000039fe6e8235c - then use scsi-35000039fe6e8235c.\n1. Creating Partitions We will first prepare a partition layout to separate the configuration for dmsetup and the remainder of the disk.\nparted /dev/disk/by-id/DISK_ID mklabel gpt parted /dev/disk/by-id/DISK_ID mkpart primary ext3 1MB 10MB parted /dev/disk/by-id/DISK_ID mkpart primary 10MB 100% This creates two partitions:\nPartition 1: A very small partition to hold important configurations on this disk Partition 2: The remainder of the drive. This is where we will be making our dmsetup magic I made the small partition 10MB, but even that may be too large. Although its more tricky to make it larger if needed, later on.\n2. Running Badblocks Scan the remainder of the disk for bad blocks:\nbadblocks -b 4096 -o badblocks-4k.txt -s /dev/disk/by-id/DISK_ID-part2 Now, you can additionally:\nAdd -n for a non-destructive read-write mode, it rewrites the entire disk with the same contents Add -w for a destructive read-write mode, it overwrites the entire disk with 4 patterns Remove -s (status reporting) if you, like me, are running this in parallel on many disks. ‚ö†Ô∏è Important: -w is destructive, it will overwrite data.\n‚ÑπÔ∏è Info: dmsetup operates on 512-byte units, so ideally we would set -b 512 to keep everything aligned, but badblocks uses 32-bit integers internally for blocks. So 512-byte blocks has a cap of a 2TB disk, 1024-byte a 4 TB disk and so on. I will operate on 4096 byte blocks, because most larger disks are this size anyways, but we\u0026rsquo;ll have to multiply all offsets later on to compensate.\n‚ÑπÔ∏è Info: If we ever need to in the future, we must run badblocks with the same block size as before. I\u0026rsquo;ve encoded the size in the filename (-4k.txt) so we can know.\n3. Prepare dmsetup and systemd Once badblocks is done, you\u0026rsquo;ll have a file filled with blocks that are considered bad. Now, we need to inverse that to get ranges that are good. You can do this manually, read the file and identify sequential sets of numbers, then write out the ranges between those numbers. F.ex, a file with the numbers 1, 2, 3, 9, 10, 17 should give ranges 0-1, 4-9, 11-17.\nI\u0026rsquo;ve prepared a bash script that can:\nPrepare a dmsetup table for the disk with the inverse of the badblocks ranges Prepare a systemd unit that can load our dmsetup device Bash script to prepare dmsetup and system configs generate_dmsetup_and_systemd_unit() { local input=\u0026#34;$1\u0026#34; local badblocks_file=\u0026#34;$2\u0026#34; local block_size=\u0026#34;$3\u0026#34; # Resolve input to a /dev/disk/by-id/ path (disk, not partition) local device=\u0026#34;\u0026#34; if [[ \u0026#34;$input\u0026#34; =~ ^/dev/disk/by-id/ ]]; then device=\u0026#34;$input\u0026#34; elif [[ \u0026#34;$input\u0026#34; =~ ^/dev/ ]]; then device=$(find /dev/disk/by-id -lname \u0026#34;*${input##*/}\u0026#34; | grep -E \u0026#39;/dev/disk/by-id/(scsi|ata|nvme|sas)-[0-9a-fA-F]+\u0026#39; | head -n1) if [[ -z \u0026#34;$device\u0026#34; ]]; then device=$(find /dev/disk/by-id -lname \u0026#34;*${input##*/}\u0026#34; | grep -E \u0026#39;/dev/disk/by-id/wwn-\u0026#39; | head -n1) fi if [[ -z \u0026#34;$device\u0026#34; ]]; then device=$(find /dev/disk/by-id -lname \u0026#34;*${input##*/}\u0026#34; | head -n1) fi else device=\u0026#34;/dev/disk/by-id/$input\u0026#34; fi if [[ ! -e \u0026#34;$device\u0026#34; || ! -b \u0026#34;$device\u0026#34; ]]; then echo \u0026#34;Error: Unable to resolve \u0026#39;$input\u0026#39; to a valid /dev/disk/by-id/ block device.\u0026#34; \u0026gt;\u0026amp;2 return 1 fi local id=\u0026#34;${device##*/}\u0026#34; local part_device=\u0026#34;${device}-part2\u0026#34; if [[ ! -e \u0026#34;$part_device\u0026#34; || ! -b \u0026#34;$part_device\u0026#34; ]]; then echo \u0026#34;Error: Expected partition device $part_device not found.\u0026#34; \u0026gt;\u0026amp;2 return 1 fi local name=\u0026#34;dm-badblocks-${id}\u0026#34; local table_file=\u0026#34;${name}.table\u0026#34; local service_file=\u0026#34;${name}.service\u0026#34; if [[ ! -f \u0026#34;$badblocks_file\u0026#34; ]]; then echo \u0026#34;Error: badblocks file not found: $badblocks_file\u0026#34; \u0026gt;\u0026amp;2 return 1 fi if [[ -z \u0026#34;$block_size\u0026#34; || \u0026#34;$block_size\u0026#34; -lt 512 ]]; then echo \u0026#34;Error: block size must be \u0026gt;= 512\u0026#34; \u0026gt;\u0026amp;2 return 1 fi if (( block_size \u0026amp; (block_size - 1) )); then echo \u0026#34;Error: block size must be a power of 2\u0026#34; \u0026gt;\u0026amp;2 return 1 fi local scale=$((block_size / 512)) local total_sectors total_sectors=$(blockdev --getsz \u0026#34;$part_device\u0026#34;) echo \u0026#34;Generating ${table_file} for $part_device...\u0026#34; # Parse/sort badblocks file (may be empty) local -a badblock_sectors while IFS= read -r line; do [[ -n \u0026#34;$line\u0026#34; ]] \u0026amp;\u0026amp; badblock_sectors+=($((line * scale))) done \u0026lt; \u0026lt;(sort -n \u0026#34;$badblocks_file\u0026#34;) # Emit a dmsetup table file in the form \u0026#34;\u0026lt;virtual_offset\u0026gt; \u0026lt;length\u0026gt; linear \u0026lt;device\u0026gt; \u0026lt;physical_offset\u0026gt;\u0026#34; if (( ${#badblock_sectors[@]} == 0 )); then { local length=$((total_sectors - 8)) echo \u0026#34;0 $length linear $part_device 8\u0026#34; } \u0026gt; \u0026#34;$table_file\u0026#34; else if (( badblock_sectors[0] \u0026lt;= 8 )); then echo \u0026#34;Error: there are badblocks on the first sectors of the disk. This is not supported by this script.\u0026#34; \u0026gt;\u0026amp;2 return 1 fi { local first_length=$((badblock_sectors[0] - 8)) echo \u0026#34;0 $first_length linear $part_device 8\u0026#34; local offset=$((first_length)) local physical_sector_prev=-1 for i in \u0026#34;${!badblock_sectors[@]}\u0026#34;; do local physical_sector=\u0026#34;${badblock_sectors[i]}\u0026#34; if (( physical_sector_prev != -1 \u0026amp;\u0026amp; physical_sector \u0026gt; physical_sector_prev + 1 )); then local start=$((physical_sector_prev + 1)) local length=$((physical_sector - start)) echo \u0026#34;$offset $length linear $part_device $start\u0026#34; offset=$((offset + length)) fi physical_sector_prev=$physical_sector done # Final range if (( physical_sector_prev \u0026lt; total_sectors - 1 )); then local start=$((physical_sector_prev + 1)) local length=$((total_sectors - start)) echo \u0026#34;$offset $length linear $part_device $start\u0026#34; fi } \u0026gt; \u0026#34;$table_file\u0026#34; fi echo \u0026#34;Generating ${service_file}...\u0026#34; local encoded_id=\u0026#34;${id//-/\u0026#39;\\\\x2d\u0026#39;}\u0026#34; cat \u0026gt; \u0026#34;$service_file\u0026#34; \u0026lt;\u0026lt;EOF [Unit] Description=Prepare dmsetup device for $name After=dev-disk-by${encoded_id}\\\\x2dpart2.device [Service] Type=oneshot ExecStart=/bin/sh -c \u0026#39;/bin/cat /etc/dmsetup/${table_file} | /sbin/dmsetup create ${name}\u0026#39; ExecStop=/sbin/dmsetup remove ${name} RemainAfterExit=true [Install] WantedBy=multi-user.target EOF echo \u0026#34;Done.\u0026#34; echo \u0026#34;-\u0026gt; Table: $PWD/$table_file\u0026#34; echo \u0026#34;-\u0026gt; Service: $PWD/$service_file\u0026#34; if (( ${#badblock_sectors[@]} == 0 )); then echo -e \u0026#34;\\033[1;31mWARNING: badblocks file is empty. Outputting a table for the whole device.\\033[0m\u0026#34; \u0026gt;\u0026amp;2 fi } # Example use: \u0026gt; generate_dmsetup_and_systemd_unit scsi-35000c500bf2dc1eb badblocks-4k.txt 4096 \u0026gt; generate_dmsetup_and_systemd_unit /dev/sdc badblocks-4k.txt 4096 \u0026gt; generate_dmsetup_and_systemd_unit /dev/disk/by-id/scsi-35000c500bf2dc1eb badblocks-4k.txt 4096 Once run, you\u0026rsquo;ll have two files in your current directory:\ndm-badblocks-DISK_ID.table \u0026ndash; dmsetup table to avoid badblocks dm-badblocks-DISK_ID.service \u0026ndash; systemd unit ‚ÑπÔ∏è Info: If, like me, you\u0026rsquo;re using ZFS, it is important that this unit loads before ZFS mounts its devices. Add this line under the [Unit] section to ensure ZFS mounts after dmsetup: Before=zfs-mount.service. You can adjust this as needed for other systems.\n4. Setting up this system Now we will prepare our running system to use the dmsetup. This step should be repeated, if you move the disk to a new system.\n# Prepare the dmsetup etc directory mkdir -p /etc/dmsetup # Copy the systemd unit cp dm-badblocks-DISK_ID.service /etc/systemd/system/ cp dm-badblocks-DISK_ID.table /etc/dmsetup/ Reload the unit, and start it. Verify it doesn\u0026rsquo;t emit any errors.\nsystemctl daemon-reload systemctl start dm-badblocks-DISK_ID Once it works, enable the service to make it auto-start on boot\nsystemctl enable dm-badblocks-DISK_ID ‚ÑπÔ∏è Info: We copy the table into /etc/dmsetup to ensure that on boot, we don\u0026rsquo;t need to first have the configuration mounted and then be able to load dmsetup. It\u0026rsquo;s better to have fewer dependencies. Step 6 below will copy in the configuration to the first partition for safekeeping, but once thats done, you don\u0026rsquo;t need to mount that partition again (until you move the disk or reinstall the OS of course).\n5. Preparing the configuration partition Copy the table, and the systemd unit to your configuration partition.\n# Make the configuration partition use ext3, a widely supported filesystem # Emphasis on small - make it 1024 byte blocks, 5% reserved space and fewer inodes mkfs.ext3 -b 1024 -m 5 -T news /dev/disk/by-id/DISK_ID-part1 mkdir /mnt/tmp mount /dev/disk/by-id/DISK_ID-part1 /mnt/tmp # Ensure we can identify this setup in the future # Do this by writing a helpful text in the beginning of our physical device, in the 4k in the beginning that is not used e2label /dev/disk/by-id/DISK_ID-part1 \u0026#34;READ ME\u0026#34; dd if=/dev/zero of=/dev/disk/by-id/DISK_ID-part2 bs=4096 count=1 conv=notrunc echo -n \u0026#34;This disk is managed by dmsetup. Do not use directly. Read the configuration on the first partition for how to use.\u0026#34; | dd of=/dev/disk/by-id/DISK_ID-part2 bs=4096 count=1 conv=notrunc # Copy in configuration files cp dm-badblocks-DISK_ID.table /mnt/tmp/ cp dm-badblocks-DISK_ID.service /mnt/tmp/ cp badblocks-4k.txt /mnt/tmp/ # Copy this blogpost to the readme printf \u0026#34;Source: https://blog.mbwarez.dk/posts/2025/04/bad-disks-dmsetup/\\nGenerated on: %s UTC\\n\\n---\\n\u0026#34; \u0026#34;$(date -u \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39;)\u0026#34; \u0026gt; /mnt/tmp/README.txt wget https://blog.mbwarez.dk/posts/2025/04/bad-disks-dmsetup/index.md -O - \u0026gt;\u0026gt; /mnt/tmp/README.txt ‚ÑπÔ∏è Info: The ext3 partition holds the configuration files (dmsetup table, systemd service) so that everything follows the disk when you move it around. Setting its label to \u0026lsquo;READ ME\u0026rsquo; hints at its purpose and ensures anyone inspecting the disk understands its role.\n‚ÑπÔ∏è Info: We\u0026rsquo;ve also ensured that partition 2 is not mountable by conventional means. This ensures that when the disk is moved to a new system, it is not accidentally identified as EXT/ZFS/FAT or whatever might actually be on it.\nSummary By using this method, you can salvage a disk with bad sectors and make it usable again without having to replace it. This approach is especially useful when working with filesystems that do not support marking bad blocks, like ZFS.\nYou can replicate this process for other disks by adjusting the disk IDs and table filenames.\n","permalink":"https://blog.mbwarez.dk/posts/2025/04/bad-disks-dmsetup/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eI have a disk with bad blocks. The filesystem I\u0026rsquo;m using (such as ZFS) doesn\u0026rsquo;t support marking bad blocks like ext did, and completely replacing the disk is costly and unnecessary. Instead, I\u0026rsquo;ve used \u003ccode\u003edmsetup\u003c/code\u003e to create a virtual disk that excludes the bad sectors, allowing the filesystem to work with the remaining good areas.\u003c/p\u003e\n\u003cp\u003eThis guide covers the process of scanning the disk, preparing a custom partition, setting up \u003ccode\u003edmsetup\u003c/code\u003e, and ensuring everything works across reboots. I\u0026rsquo;ve additionally included steps to ensure that the \u003ccode\u003edmsetup\u003c/code\u003e configuration follows the disk, ensuring you don\u0026rsquo;t loose that critical piece of information.\u003c/p\u003e","title":"Using dmsetup to Salvage Disks with Bad Blocks"},{"content":" ‚ÑπÔ∏è Info: This post was linked in the WLED discussions and the script may make it to the WLED project.\nIntroduction WLED is a powerful open-source solution for controlling addressable LEDs over Wi-Fi, making it popular for DIY smart lighting projects. However, maintaining backups of your WLED configurations can be tedious, especially when managing multiple devices.\nIn this post, I\u0026rsquo;ll demonstrate a simple bash-based backup solution that discovers WLED devices on your network, pulls their configurations, and saves them locally for easy restoration. The scripts are intended for Linux-based systems and can be scheduled with cron for fully automated backups.\nRequirements The scripts presented in this post rely on the following dependencies:\nwled with mDNS enabled: For discovering WLED devices via mDNS.\nIf not already enabled, it can be set up in Config -\u0026gt; WiFi setup -\u0026gt; set a name in mDNS This is critical for discovery of devices avahi-utils (avahi-browse): For discovering WLED devices via mDNS.\nInstallation (Debian-based systems): sudo apt install avahi-utils jq: For pretty-printing JSON configuration files.\nInstallation (Debian-based systems): sudo apt install jq curl: For making HTTP requests to WLED devices to fetch configuration data.\nInstallation (if not already present): sudo apt install curl Ensure all dependencies are installed before proceeding. The jq dependency is optional but highly recommended for human-readable backups.\nBacking up a single instance It\u0026rsquo;s fairly easy to curl our way to one backup. We simply fetch http://host/presets.json and http://host/cfg.json. Then we\u0026rsquo;re done. I\u0026rsquo;ve cooked up this backup-one.sh which will:\nBe called like backup-one.sh HostName Output HostName.cfg.json and HostName.presets.json Only output those files, if successful #!/bin/bash # Check if a hostname argument is provided if [ \u0026#34;$#\u0026#34; -ne 1 ]; then echo \u0026#34;Usage: $0 \u0026lt;hostname\u0026gt;\u0026#34; exit 1 fi if ! command -v jq \u0026amp;\u0026gt; /dev/null; then echo \u0026#34;jq is not installed. Proceeding without pretty-printing JSON files.\u0026#34; JQ_AVAILABLE=0 else JQ_AVAILABLE=1 fi hostname=$1 backup_dir=\u0026#34;/mnt/systems/backup/source/wled/\u0026#34; # Create the backup directory if it doesn\u0026#39;t exist mkdir -p \u0026#34;$backup_dir\u0026#34; # Function to fetch a file using curl fetch_file() { local url=$1 local dest=$2 # Use curl to fetch the file. Exit with the curl exit code if it fails. if ! curl -s -o \u0026#34;$dest\u0026#34; \u0026#34;$url\u0026#34;; then exit $? # Exit with the curl command\u0026#39;s exit code fi # If jq is available and pretty-printing is requested, pretty-print the JSON file. if [[ $JQ_AVAILABLE -eq 1 ]]; then jq . \u0026#34;$dest\u0026#34; \u0026gt; \u0026#34;${dest}.tmp\u0026#34; \u0026amp;\u0026amp; mv \u0026#34;${dest}.tmp\u0026#34; \u0026#34;$dest\u0026#34; fi } # Fetch cfg.json cfg_url=\u0026#34;http://$hostname/cfg.json\u0026#34; cfg_dest=\u0026#34;${backup_dir}${hostname}.cfg.json\u0026#34; fetch_file \u0026#34;$cfg_url\u0026#34; \u0026#34;$cfg_dest\u0026#34; # Fetch presets.json presets_url=\u0026#34;http://$hostname/presets.json\u0026#34; presets_dest=\u0026#34;${backup_dir}${hostname}.presets.json\u0026#34; fetch_file \u0026#34;$presets_url\u0026#34; \u0026#34;$presets_dest\u0026#34; echo \u0026#34;Backup of $hostname completed successfully.\u0026#34; Discovering WLED instances WLED is discoverable (at least it can be made to be) over mDNS which is great. This allows us to find all instances quickly and efficiently, as they\u0026rsquo;ll respond when queried for the _wled._tcp service type. This TLD (_tcp) is part of the service discovery piece of DNS.\nExample query:\n# avahi-browse _wled._tcp --terminate -r -p +;enp0s25;IPv4;wled-christmaslights;_wled._tcp;local +;enp0s25;IPv4;wled-stairs;_wled._tcp;local =;enp0s25;IPv4;wled-stairs;_wled._tcp;local;wled-stairs.local;192.168.1.203;80;\u0026#34;mac=94e68695be28\u0026#34; =;enp0s25;IPv4;wled-christmaslights;_wled._tcp;local;wled-christmaslights.local;192.168.1.199;80;\u0026#34;mac=94e68687fa24\u0026#34; The above shows two instances responding to our query. Avahi-browse will terminate after no more responses show up.\nPutting it together I\u0026rsquo;ve put together the below backup-discover.sh script which will do the above and call into backup-one.sh for each instance it finds. I call this on a cron job every week, and then snapshot the resulting directory of configs with my favourite backup tool that copies them all off.\nNow I have weekly snapshots of my wled devices - and I don\u0026rsquo;t need to configure anything :)\n#!/bin/bash # Define the service type you are interested in service_type=\u0026#34;_wled._tcp\u0026#34; # Path to the backup script backup_script=\u0026#34;$(dirname \u0026#34;$0\u0026#34;)/backup-one.sh\u0026#34; # Check if the backup script exists and is executable if [ ! -x \u0026#34;$backup_script\u0026#34; ]; then echo \u0026#34;Backup script $backup_script not found or is not executable.\u0026#34; exit 1 fi # Use avahi-browse to find services, parse the output to get hostnames mapfile -t hostnames \u0026lt; \u0026lt;(avahi-browse \u0026#34;$service_type\u0026#34; --terminate -r -p | awk -F\u0026#39;;\u0026#39; \u0026#39;/^=/ {print $7}\u0026#39;) # Check if any hostnames were found if [ ${#hostnames[@]} -eq 0 ]; then echo \u0026#34;No hosts found for service type $service_type.\u0026#34; exit 0 fi # Remove duplicate hostnames unique_hostnames=($(printf \u0026#34;%s\\n\u0026#34; \u0026#34;${hostnames[@]}\u0026#34; | sort -u)) # Initialize a variable to track if any backup has failed backup_failed=0 # Execute backup script for each unique hostname for hostname in \u0026#34;${unique_hostnames[@]}\u0026#34;; do echo \u0026#34;Backing up $hostname...\u0026#34; $backup_script \u0026#34;$hostname\u0026#34; backup_result=$? if [ $backup_result -ne 0 ]; then echo \u0026#34;Backup for $hostname failed with exit code $backup_result.\u0026#34; backup_failed=1 # Mark that a backup has failed fi done # Exit with a code if any backup failed if [ $backup_failed -ne 0 ]; then echo \u0026#34;One or more backups failed.\u0026#34; exit 2 # You can choose an appropriate exit code fi echo \u0026#34;All backups completed successfully.\u0026#34; ","permalink":"https://blog.mbwarez.dk/posts/2025/03/wled-backup-script/","summary":"\u003cblockquote\u003e\n\u003cp\u003e‚ÑπÔ∏è Info: This post was \u003ca href=\"https://github.com/wled/WLED/discussions/4621\"\u003elinked in the WLED discussions\u003c/a\u003e and the script may \u003ca href=\"https://github.com/wled/WLED/pull/4625\"\u003emake it to the WLED project\u003c/a\u003e.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://kno.wled.ge/\"\u003eWLED\u003c/a\u003e is a powerful open-source solution for controlling addressable LEDs over Wi-Fi, making it popular for DIY smart lighting projects. However, maintaining backups of your WLED configurations can be tedious, especially when managing multiple devices.\u003c/p\u003e\n\u003cp\u003eIn this post, I\u0026rsquo;ll demonstrate a simple bash-based backup solution that discovers WLED devices on your network, pulls their configurations, and saves them locally for easy restoration. The scripts are intended for Linux-based systems and can be scheduled with cron for fully automated backups.\u003c/p\u003e","title":"WLED Backup script"},{"content":"I had a use case for EF Core where I wanted to query a database view while still supporting classic add/update/delete methods on the base table. Specifically, I wanted to enrich entities with computed values, like a lookup or label, but allow full CRUD support.\nExample Problem Suppose we have two entities:\nEntity: (Id, DeviceId) Friendly: (DeviceId, FriendlyName) The goal is to filter Entity records by FriendlyName, even though it‚Äôs not part of the table directly.\nThings That Didn\u0026rsquo;t Work Computed Columns: MySQL and PostgreSQL restrict computed columns to functions on the same table. Mapping FriendlyName into Entity: Either EF doesn\u0026rsquo;t query the column, or tries to fetch it from the table (not the view). Mapping to Both a Table and a View: Works until EF tries to return values from insert, then fails as the base table lacks the extra field. Entity Splitting/Table Splitting: Requires the relationship to always exist and be strict FK-based. SplitToTable/SplitToView in EF7: Doesn‚Äôt support mixing views and tables in one entity. Possible Solutions Auto-Included Relationship with No Foreign Key class Entity { string Id; string DeviceId; Friendly FriendlyEntity; } class Friendly { string DeviceId; string FriendlyName; } modelBuilder.Entity\u0026lt;Entity\u0026gt;() .HasOne(e =\u0026gt; e.FriendlyEntity) .WithMany() .HasForeignKey(e =\u0026gt; e.DeviceId) .HasPrincipalKey(f =\u0026gt; f.DeviceId) .IsRequired(false) .OnDelete(DeleteBehavior.ClientNoAction); entity.Navigation(e =\u0026gt; e.FriendlyEntity).AutoInclude(); This works if you suppress the generated FK constraint in migrations. Otherwise, EF will enforce the FK and prevent inserts for unmatched values.\nView + Stored Procedures Create a view that joins Entity and Friendly, and map Entity to that view:\nentity.ToView(\u0026#34;entity_view\u0026#34;); Then configure insert/update/delete via stored procedures:\nentity.InsertUsingStoredProcedure(\u0026#34;entity_sp_insert\u0026#34;, sp =\u0026gt; { sp.HasParameter(e =\u0026gt; e.Id, p =\u0026gt; p.IsInputOutput()); sp.HasParameter(e =\u0026gt; e.DeviceId); // Skip FriendlyName }); entity.ToTable(\u0026#34;entity_table\u0026#34;, t =\u0026gt; t.ExcludeFromMigrations()); Note: EF Core bug #28703 prevents stored procedures from working with views directly, so map to the table but mark it excluded from migrations.\nThis lets EF query via the view and write via the procedures.\nConclusion You can use views in EF Core while manipulating tables via stored procedures or relationship joins. Just be aware of the limitations and quirks in the provider and EF version.\n","permalink":"https://blog.mbwarez.dk/posts/2023/entity-framework-core-querying-views-manipulating-tables/","summary":"\u003cp\u003eI had a use case for EF Core where I wanted to query a database view while still supporting classic add/update/delete methods on the base table. Specifically, I wanted to enrich entities with computed values, like a lookup or label, but allow full CRUD support.\u003c/p\u003e\n\u003ch2 id=\"example-problem\"\u003eExample Problem\u003c/h2\u003e\n\u003cp\u003eSuppose we have two entities:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eEntity\u003c/code\u003e: \u003ccode\u003e(Id, DeviceId)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eFriendly\u003c/code\u003e: \u003ccode\u003e(DeviceId, FriendlyName)\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe goal is to filter \u003ccode\u003eEntity\u003c/code\u003e records by \u003ccode\u003eFriendlyName\u003c/code\u003e, even though it‚Äôs not part of the table directly.\u003c/p\u003e","title":"Entity Framework Core: Querying views, but manipulating tables"},{"content":"In EF Core, you can easily filter to a list of known values using LINQ:\nint[] ids = { 1, 3, 7 }; myContext.Posts.Where(s =\u0026gt; ids.Contains(s.Id)); But what if the list of values includes composite keys, like Type and Name?\nvar filterBy = new[] { (PostTypes.Blog, \u0026#34;First\u0026#34;), (PostTypes.KnowledgeBase, \u0026#34;Last\u0026#34;) }; myContext.Posts.Where(s =\u0026gt; filterBy.Contains((s.Type, s.Name))); // But how? There‚Äôs no direct Contains() support for tuples or composite keys in EF Core. A Stack Overflow post outlines several options. Here, I‚Äôll focus on Option 6 ‚Äî building an expression tree to generate a SQL query like:\nSELECT * FROM Posts WHERE (Type = 1 AND Name = \u0026#39;First\u0026#39;) OR (Type = 2 AND Name = \u0026#39;Last\u0026#39;); It\u0026rsquo;s All Expressions The code is available on GitHub.\nLet‚Äôs replicate the following filter:\ncontext.Posts.Where(post =\u0026gt; (post.Author == \u0026#34;Mike\u0026#34; \u0026amp;\u0026amp; post.Title == \u0026#34;Intro to mysql\u0026#34;) || (post.Author == \u0026#34;Mike\u0026#34; \u0026amp;\u0026amp; post.Title == \u0026#34;How the world works\u0026#34;)) We construct an expression tree manually:\nParameterExpression postArgument = Expression.Parameter(typeof(BlogPost), \u0026#34;post\u0026#34;); MemberExpression propertyAuthor = Expression.Property(postArgument, nameof(BlogPost.Author)); MemberExpression propertyTitle = Expression.Property(postArgument, nameof(BlogPost.Title)); ConstantExpression constantAuthor = Expression.Constant(\u0026#34;Mike\u0026#34;); ConstantExpression constantTitle = Expression.Constant(\u0026#34;Intro to mysql\u0026#34;); BinaryExpression andExpr = Expression.AndAlso( Expression.Equal(propertyAuthor, constantAuthor), Expression.Equal(propertyTitle, constantTitle)); Combine multiple AND conditions using OR:\nBinaryExpression orExpression = Expression.OrElse(firstAnd, secondAnd); orExpression = Expression.OrElse(orExpression, thirdAnd); Wrap it in a lambda:\nType delegateFunc = typeof(Func\u0026lt;,\u0026gt;).MakeGenericType(typeof(BlogPost), typeof(bool)); Expression\u0026lt;Func\u0026lt;BlogPost, bool\u0026gt;\u0026gt; lambda = (Expression\u0026lt;Func\u0026lt;BlogPost, bool\u0026gt;\u0026gt;)Expression.Lambda(delegateFunc, orExpression, postArgument); Use it in your query:\ncontext.Posts.Where(lambda); Result The query now supports filtering on multiple composite key pairs, and translates correctly to SQL.\nBe sure to check out the working example on GitHub ‚Äî it also prints out the SQL, so you can verify what‚Äôs happening behind the scenes.\n","permalink":"https://blog.mbwarez.dk/posts/2021/entityframework-core-composite-key-filtering/","summary":"\u003cp\u003eIn EF Core, you can easily filter to a list of known values using LINQ:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-csharp\" data-lang=\"csharp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003eids\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"m\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"m\"\u003e7\u003c/span\u003e \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emyContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ePosts\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eWhere\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eids\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eContains\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eId\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBut what if the list of values includes composite keys, like \u003ccode\u003eType\u003c/code\u003e and \u003ccode\u003eName\u003c/code\u003e?\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-csharp\" data-lang=\"csharp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003efilterBy\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ePostTypes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBlog\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;First\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ePostTypes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eKnowledgeBase\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Last\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emyContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ePosts\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eWhere\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003efilterBy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eContains\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eType\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eName\u003c/span\u003e\u003cspan class=\"p\"\u003e)));\u003c/span\u003e \u003cspan class=\"c1\"\u003e// But how?\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThere‚Äôs no direct \u003ccode\u003eContains()\u003c/code\u003e support for tuples or composite keys in EF Core. A \u003ca href=\"https://stackoverflow.com/questions/26198860/entityframework-contains-query-of-composite-key\"\u003eStack Overflow post\u003c/a\u003e outlines several options. Here, I‚Äôll focus on Option 6 ‚Äî building an expression tree to generate a SQL query like:\u003c/p\u003e","title":"EntityFramework Core ‚Äì Composite key filtering"},{"content":"At work, we maintain a product with 400+ projects spread over 15 repositories. Making changes across them is painful‚Äîespecially when debugging SDK-level code and publishing local packages repeatedly.\nTo make this smoother, I created a tool: ElephantProject (also on NuGet).\nElephantProject swaps NuGet \u0026lt;PackageReference\u0026gt;s with \u0026lt;ProjectReference\u0026gt;s, and generates solution files for local dev.\nThese changes are never committed‚Äîthis is for local development only.\nUse Case ‚Äì Refactoring In my local dev directory (called \u0026ldquo;Work\u0026rdquo;), I clone all the repositories. Then I run:\nelephant-project rewrite -d Work This scans all .csproj files and replaces package references with project references, matching by PackageId or AssemblyName. I can then build locally without republishing anything.\nTo create a solution file:\nelephant-project sln -d Work MySolution.sln -i MyApp/** It includes all app projects and their dependencies.\nI typically maintain:\nelephant-project sln -d Work Full.sln elephant-project sln -d Work App.sln -i MyApp/** elephant-project sln -d Work AppAndSdk.sln -i MyApp/** -i MySdk/** Use Case ‚Äì Syncing Solution Files In many repos, we have multiple applications. Each app has its own .sln, plus a repo-wide one. Solution files fall out of sync easily.\nWith ElephantProject, I automate syncing:\n# Create root-level sln elephant-project sln Root.sln -i Applications/** # Create one per app for app in Applications/*; do elephant-project sln \u0026#34;$app/$app.sln\u0026#34; -i \u0026#34;$app/**\u0026#34; done All .sln files stay up to date‚Äîwithout manual tweaks.\nThis tool has massively simplified multi-repo dev and SDK testing for us.\n","permalink":"https://blog.mbwarez.dk/posts/2021/introducing-elephant-projects-cross-repository-refactoring/","summary":"\u003cp\u003eAt work, we maintain a product with 400+ projects spread over 15 repositories. Making changes across them is painful‚Äîespecially when debugging SDK-level code and publishing local packages repeatedly.\u003c/p\u003e\n\u003cp\u003eTo make this smoother, I created a tool: \u003ca href=\"https://github.com/LordMike/MBW.Tools.ElephantProject\"\u003eElephantProject\u003c/a\u003e (also on \u003ca href=\"https://www.nuget.org/packages/MBW.Tools.ElephantProject\"\u003eNuGet\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eElephantProject swaps NuGet \u003ccode\u003e\u0026lt;PackageReference\u0026gt;\u003c/code\u003es with \u003ccode\u003e\u0026lt;ProjectReference\u0026gt;\u003c/code\u003es, and generates solution files for local dev.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThese changes are never committed‚Äîthis is for local development only.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"use-case--refactoring\"\u003eUse Case ‚Äì Refactoring\u003c/h2\u003e\n\u003cp\u003eIn my local dev directory (called \u0026ldquo;Work\u0026rdquo;), I clone all the repositories. Then I run:\u003c/p\u003e","title":"Introducing Elephant Projects - Cross-repository refactoring"},{"content":"This is part of my guide on how I manage multiple GitHub repositories. This post focuses on streamlining shared content, such as workflows and configuration files. Back to main guide.\nFile Sets I define sets of reusable files that can be applied across multiple repositories:\nstandardContent: Generic files like .gitignore standardDotnetNuget: Shared .NET workflows and Directory.Build.props standardDocker: Docker-related workflows and .dockerignore These sets are declared in repos.json:\n{ \u0026#34;content\u0026#34;: { \u0026#34;standardContent\u0026#34;: { \u0026#34;.gitignore\u0026#34;: \u0026#34;standard_content/.gitignore\u0026#34; }, \u0026#34;standardDocker\u0026#34;: { \u0026#34;.github/workflows/docker-dev.yml\u0026#34;: \u0026#34;standard_content/docker-dev.yml\u0026#34; } }, \u0026#34;repositories\u0026#34;: { \u0026#34;LordMike/MBW.BlueRiiot2MQTT\u0026#34;: { \u0026#34;standardContent\u0026#34;: true, \u0026#34;standardDocker\u0026#34;: true } } } Each repository opts into content sets by enabling the respective boolean key.\nApplying Content with gh-standard-content I created a tool that syncs content into repositories and manages pull requests for changes:\nMBW.Tools.GhStandardContent\nInstallation Install the tool locally using a tool manifest:\ndotnet new tool-manifest dotnet tool install MBW.Tools.GhStandardContent Usage Run it using a script:\n# DoStandardContent.ps1 dotnet tool restore dotnet tool run gh-standard-content -t MY_GH_TOKEN repos.json This scans the repositories, detects content drift, and creates PRs where updates are needed.\nSimple, powerful, and version-controlled content management for your GitHub repos.\n","permalink":"https://blog.mbwarez.dk/posts/2021/gh-mass-administration-content/","summary":"\u003cp\u003eThis is part of my guide on how I manage multiple GitHub repositories. This post focuses on streamlining shared content, such as workflows and configuration files. \u003ca href=\"/posts/2021/gh-mass-administration/\"\u003eBack to main guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"file-sets\"\u003eFile Sets\u003c/h2\u003e\n\u003cp\u003eI define sets of reusable files that can be applied across multiple repositories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003estandardContent\u003c/code\u003e: Generic files like \u003ccode\u003e.gitignore\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003estandardDotnetNuget\u003c/code\u003e: Shared \u003ccode\u003e.NET\u003c/code\u003e workflows and \u003ccode\u003eDirectory.Build.props\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003estandardDocker\u003c/code\u003e: Docker-related workflows and \u003ccode\u003e.dockerignore\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese sets are declared in \u003ccode\u003erepos.json\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;standardContent\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026#34;.gitignore\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;standard_content/.gitignore\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;standardDocker\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026#34;.github/workflows/docker-dev.yml\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;standard_content/docker-dev.yml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;repositories\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;LordMike/MBW.BlueRiiot2MQTT\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026#34;standardContent\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"nt\"\u003e\u0026#34;standardDocker\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eEach repository opts into content sets by enabling the respective boolean key.\u003c/p\u003e","title":"GH Mass-administration: Content"},{"content":"This is a part of my guide to how I manage multiple GitHub repositories. This post focuses on configuring repository settings on GitHub using Terraform. Back to main guide.\nRepository Management with Terraform I use Terraform to declaratively configure:\nRepo metadata: description, topics, features Branch settings: default branch and protection rules GitHub Actions secrets: shared credentials for NuGet and Docker Example Configuration Github.tf defines:\nlocals { github_owner = \u0026#34;LordMike\u0026#34; github_token = \u0026#34;REPLACE_ME\u0026#34; repositories = jsondecode(file(\u0026#34;repos.json\u0026#34;)).repositories repos = keys(local.repositories) repos_public = [for r in local.repos : r if lookup(local.repositories[r], \u0026#34;public\u0026#34;, true)] nuget_repos = [for r in local.repos : r if lookup(local.repositories[r], \u0026#34;nuget\u0026#34;, true)] docker_repos = [for r in local.repos : r if lookup(local.repositories[r], \u0026#34;docker\u0026#34;, false)] docker_username = \u0026#34;lordmike\u0026#34; docker_key = \u0026#34;REPLACE_ME\u0026#34; nuget_key = \u0026#34;REPLACE_ME\u0026#34; } provider \u0026#34;github\u0026#34; { owner = local.github_owner token = local.github_token } resource \u0026#34;github_repository\u0026#34; \u0026#34;repository\u0026#34; { for_each = toset(local.repos) name = split(\u0026#34;/\u0026#34;, each.key)[1] description = lookup(local.repositories[each.key], \u0026#34;description\u0026#34;, \u0026#34;\u0026#34;) topics = lookup(local.repositories[each.key], \u0026#34;topics\u0026#34;, null) has_issues = lookup(local.repositories[each.key], \u0026#34;has_issues\u0026#34;, true) has_wiki = lookup(local.repositories[each.key], \u0026#34;has_wiki\u0026#34;, false) has_projects = lookup(local.repositories[each.key], \u0026#34;has_projects\u0026#34;, false) has_downloads = lookup(local.repositories[each.key], \u0026#34;has_downloads\u0026#34;, false) delete_branch_on_merge = lookup(local.repositories[each.key], \u0026#34;delete_branch_on_merge\u0026#34;, true) } resource \u0026#34;github_branch_default\u0026#34; \u0026#34;default_branch\u0026#34; { for_each = toset(local.repos) repository = split(\u0026#34;/\u0026#34;, each.key)[1] branch = \u0026#34;master\u0026#34; } resource \u0026#34;github_branch_protection\u0026#34; \u0026#34;protect_master\u0026#34; { for_each = toset(local.repos_public) repository_id = split(\u0026#34;/\u0026#34;, each.key)[1] pattern = \u0026#34;master\u0026#34; enforce_admins = false allows_deletions = false allows_force_pushes = false } resource \u0026#34;github_actions_secret\u0026#34; \u0026#34;nuget_key\u0026#34; { for_each = toset(local.nuget_repos) repository = split(\u0026#34;/\u0026#34;, each.key)[1] secret_name = \u0026#34;NUGET_KEY\u0026#34; plaintext_value = local.nuget_key } resource \u0026#34;github_actions_secret\u0026#34; \u0026#34;docker_username\u0026#34; { for_each = toset(local.docker_repos) repository = split(\u0026#34;/\u0026#34;, each.key)[1] secret_name = \u0026#34;DOCKER_USERNAME\u0026#34; plaintext_value = local.docker_username } resource \u0026#34;github_actions_secret\u0026#34; \u0026#34;docker_key\u0026#34; { for_each = toset(local.docker_repos) repository = split(\u0026#34;/\u0026#34;, each.key)[1] secret_name = \u0026#34;DOCKER_KEY\u0026#34; plaintext_value = local.docker_key } Tips Use for_each and filtered locals (e.g. docker_repos) to simplify resource declarations Use lookup to define defaults and override per-repo settings Terraform Imports (for existing repos) Use terraform import with escaped resource keys:\nterraform import \u0026#39;github_repository.repository[\u0026#34;LordMike/MBW.Utilities.ReflectedCast\u0026#34;]\u0026#39; LordMike/MBW.Utilities.ReflectedCast terraform import \u0026#39;github_branch_default.default_branch[\u0026#34;LordMike/MBW.Utilities.ReflectedCast\u0026#34;]\u0026#39; LordMike/MBW.Utilities.ReflectedCast Apply Changes terraform refresh # Fetch GitHub state terraform apply # Preview and apply terraform apply -refresh=false # Apply without refreshing state This setup allows me to declaratively manage all my GitHub repos at scale.\n","permalink":"https://blog.mbwarez.dk/posts/2021/gh-mass-administration-terraform/","summary":"\u003cp\u003eThis is a part of my guide to how I manage multiple GitHub repositories. This post focuses on configuring repository settings on GitHub using \u003ca href=\"https://www.terraform.io/\"\u003eTerraform\u003c/a\u003e. \u003ca href=\"/posts/2021/gh-mass-administration/\"\u003eBack to main guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"repository-management-with-terraform\"\u003eRepository Management with Terraform\u003c/h2\u003e\n\u003cp\u003eI use Terraform to declaratively configure:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRepo metadata: description, topics, features\u003c/li\u003e\n\u003cli\u003eBranch settings: default branch and protection rules\u003c/li\u003e\n\u003cli\u003eGitHub Actions secrets: shared credentials for NuGet and Docker\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"example-configuration\"\u003eExample Configuration\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eGithub.tf\u003c/code\u003e defines:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-hcl\" data-lang=\"hcl\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003elocals\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  github_owner\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;LordMike\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  github_token\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;REPLACE_ME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repositories\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003ejsondecode\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003efile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;repos.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)).\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repos\u003c/span\u003e            \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003ekeys\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repos_public\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;public\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  nuget_repos\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;nuget\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  docker_repos\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos\u003c/span\u003e \u003cspan class=\"err\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003er\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;docker\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e)]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  docker_username\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;lordmike\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  docker_key\u003c/span\u003e       \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;REPLACE_ME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  nuget_key\u003c/span\u003e        \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;REPLACE_ME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eprovider\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  owner\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003egithub_owner\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  token\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003egithub_token\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_repository\u0026#34; \u0026#34;repository\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  name\u003c/span\u003e        \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  description\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;description\u0026#34;, \u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  topics\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;topics\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  has_issues\u003c/span\u003e             \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;has_issues\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  has_wiki\u003c/span\u003e               \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;has_wiki\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  has_projects\u003c/span\u003e           \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;has_projects\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  has_downloads\u003c/span\u003e          \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;has_downloads\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  delete_branch_on_merge\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elookup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepositories\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;delete_branch_on_merge\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_branch_default\u0026#34; \u0026#34;default_branch\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repository\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  branch\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;master\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_branch_protection\u0026#34; \u0026#34;protect_master\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003erepos_public\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repository_id\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  pattern\u003c/span\u003e             \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;master\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  enforce_admins\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  allows_deletions\u003c/span\u003e    \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  allows_force_pushes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kt\"\u003efalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_actions_secret\u0026#34; \u0026#34;nuget_key\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003enuget_repos\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repository\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  secret_name\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;NUGET_KEY\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  plaintext_value\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003enuget_key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_actions_secret\u0026#34; \u0026#34;docker_username\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003edocker_repos\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repository\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  secret_name\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;DOCKER_USERNAME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  plaintext_value\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003edocker_username\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eresource\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;github_actions_secret\u0026#34; \u0026#34;docker_key\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  for_each\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003etoset\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003edocker_repos\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  repository\u003c/span\u003e      \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;/\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eeach\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003ekey\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  secret_name\u003c/span\u003e     \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;DOCKER_KEY\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003e  plaintext_value\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003elocal\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"k\"\u003edocker_key\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"tips\"\u003eTips\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eUse \u003ccode\u003efor_each\u003c/code\u003e and filtered locals (e.g. \u003ccode\u003edocker_repos\u003c/code\u003e) to simplify resource declarations\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003elookup\u003c/code\u003e to define defaults and override per-repo settings\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"terraform-imports-for-existing-repos\"\u003eTerraform Imports (for existing repos)\u003c/h2\u003e\n\u003cp\u003eUse \u003ccode\u003eterraform import\u003c/code\u003e with escaped resource keys:\u003c/p\u003e","title":"GH Mass-administration: Terraform"},{"content":"This is a short guide on how to consume packages from my GitHub packages feed. The official docs are here.\nNotes: How to find your NuGet.Config My feed URL: https://nuget.pkg.github.com/LordMike/index.json You must authenticate using a GitHub access token with read:packages permission ‚Äî create one here. The config file must exist ‚Äî use dotnet new nugetconfig to create it. Method A: Add source user-wide (CLI) dotnet new nugetconfig dotnet nuget add source \\ -n gh-lordmike \\ https://nuget.pkg.github.com/LordMike/index.json \\ -u MyGithubUser \\ -p MyGithubToken This adds a user-wide source, allowing all projects to consume from it. On Windows, the password is encrypted on disk.\nMethod B: Add source to individual project You can add the config to a single project with a local NuGet.Config file:\ndotnet new nugetconfig dotnet nuget add source \\ -n gh-lordmike \\ https://nuget.pkg.github.com/LordMike/index.json \\ --configfile NuGet.Config \\ -u MyGithubUser \\ -p MyGithubToken Note on Sharing If you share the NuGet.Config file across multiple machines, auth may fail since the token is encrypted. You can optionally store it in plain text:\n--store-password-in-clear-text This is fine for read-only tokens with the read:packages scope (recommended).\nHappy packaging! üì¶\n","permalink":"https://blog.mbwarez.dk/posts/2021/consuming-my-nuget-packages-from-github/","summary":"\u003cp\u003eThis is a short guide on how to consume packages \u003ca href=\"https://github.com/LordMike?tab=packages\"\u003efrom my GitHub packages feed\u003c/a\u003e. The \u003ca href=\"https://docs.github.com/en/packages/guides/configuring-dotnet-cli-for-use-with-github-packages#installing-a-package\"\u003eofficial docs are here\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"notes\"\u003eNotes:\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior#config-file-locations-and-uses\"\u003eHow to find your NuGet.Config\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMy feed URL: \u003ccode\u003ehttps://nuget.pkg.github.com/LordMike/index.json\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eYou \u003cstrong\u003emust\u003c/strong\u003e authenticate using a GitHub access token with \u003ccode\u003eread:packages\u003c/code\u003e permission ‚Äî \u003ca href=\"https://github.com/settings/tokens\"\u003ecreate one here\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eThe config file must exist ‚Äî use \u003ccode\u003edotnet new nugetconfig\u003c/code\u003e to create it.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"method-a-add-source-user-wide-cli\"\u003eMethod A: Add source user-wide (CLI)\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edotnet new nugetconfig\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edotnet nuget add \u003cspan class=\"nb\"\u003esource\u003c/span\u003e \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  -n gh-lordmike \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  https://nuget.pkg.github.com/LordMike/index.json \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  -u MyGithubUser \u003cspan class=\"se\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"se\"\u003e\u003c/span\u003e  -p MyGithubToken\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis adds a user-wide source, allowing all projects to consume from it. On Windows, the password is encrypted on disk.\u003c/p\u003e","title":"Consuming NuGet packages from my GitHub"},{"content":"This is a collection of notes on how I manage multiple GitHub repositories. All repositories under my account are maintained using this system.\nFeatures I need the following:\nStandardized repository configuration ‚Äî Easily change topics, descriptions, settings across all repos. Unified GitHub Actions workflows ‚Äî Shared build, test, release pipelines (e.g., NuGet, Docker Hub). Synchronized repository content ‚Äî Shared files like .gitignore, Directory.Build.props, and CI/CD workflows. In short, I want to template my repositories‚Äîbut also update those templates over time.\nParts This guide is split into parts:\nGH Mass-administration: Terraform GH Mass-administration: Content Specification All repositories are defined in a central repos.json file:\n{ \u0026#34;content\u0026#34;: { \u0026#34;standardContent\u0026#34;: { \u0026#34;.gitignore\u0026#34;: \u0026#34;standard_content/.gitignore\u0026#34; }, \u0026#34;standardDotnetNuget\u0026#34;: { \u0026#34;.github/workflows/dotnet.yml\u0026#34;: \u0026#34;standard_content/dotnet.yml\u0026#34;, \u0026#34;.github/workflows/nuget.yml\u0026#34;: \u0026#34;standard_content/nuget.yml\u0026#34;, \u0026#34;Directory.Build.props\u0026#34;: \u0026#34;standard_content/Directory.Build.props\u0026#34; } }, \u0026#34;repositories\u0026#34;: { \u0026#34;MBW.BlueRiiot2MQTT\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Utility to map between Blue Riiots pool API, and Home Assistant MQTT\u0026#34;, \u0026#34;topics\u0026#34;: [\u0026#34;hass\u0026#34;, \u0026#34;home-assistant\u0026#34;, \u0026#34;mqtt\u0026#34;, \u0026#34;blue-riiot\u0026#34;, \u0026#34;pool\u0026#34;], \u0026#34;docker\u0026#34;: true, \u0026#34;nuget\u0026#34;: false, \u0026#34;standardContent\u0026#34;: true }, \u0026#34;TMDbLib\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;C#.Net library for TheMovieDB\u0026#34;, \u0026#34;topics\u0026#34;: [\u0026#34;tmdb\u0026#34;, \u0026#34;movies\u0026#34;, \u0026#34;themoviedb\u0026#34;], \u0026#34;has_wiki\u0026#34;: true, \u0026#34;standardContent\u0026#34;: true, \u0026#34;standardDotnetNuget\u0026#34;: true } } } Each repo entry defines descriptive metadata and flags used by automation tools. Follow the linked posts for implementation details.\n","permalink":"https://blog.mbwarez.dk/posts/2021/gh-mass-administration/","summary":"\u003cp\u003eThis is a collection of notes on how I manage multiple GitHub repositories. All repositories \u003ca href=\"https://github.com/lordMike/\"\u003eunder my account\u003c/a\u003e are maintained using this system.\u003c/p\u003e\n\u003ch2 id=\"features\"\u003eFeatures\u003c/h2\u003e\n\u003cp\u003eI need the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStandardized repository configuration\u003c/strong\u003e ‚Äî Easily change topics, descriptions, settings across all repos.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUnified GitHub Actions workflows\u003c/strong\u003e ‚Äî Shared build, test, release pipelines (e.g., NuGet, Docker Hub).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSynchronized repository content\u003c/strong\u003e ‚Äî Shared files like \u003ccode\u003e.gitignore\u003c/code\u003e, \u003ccode\u003eDirectory.Build.props\u003c/code\u003e, and CI/CD workflows.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn short, I want to template my repositories‚Äîbut also update those templates over time.\u003c/p\u003e","title":"Mass-administration of GitHub repositories"},{"content":"Sometimes you need to rename an Elasticsearch index‚Äîmaybe to reuse the name for an alias. Officially, this isn\u0026rsquo;t supported. But with some manual edits and caution, it can be done.\n‚ö†Ô∏è Warning: This is dangerous and unsupported. Back up your data first.\nRecommended Alternatives Reindex API Snapshot and restore Index split If these don‚Äôt work for your case, read on.\nThe Hacky Method Stop the Elasticsearch node.\nFind the metadata files:\ngrep -rF --include \u0026#39;*.st\u0026#39; \u0026#39;my-old-index\u0026#39; data/ You\u0026rsquo;ll usually find matches in state-*.st files in index folders. Sometimes also in global-*.st files. Edit each match using a hex editor:\nReplace my-old-index with my-new-index. Keep lengths equal to preserve file structure. Recalculate the CRC32 checksum:\nMany editors like HxD support this. CRC32 covers the entire file except the last 8 bytes. Only the last 4 bytes (of those 8) are used. Double-check:\nRe-run the grep to ensure all instances were changed. Restart Elasticsearch.\nNotes \u0026amp; Sources CodecUtil docs explain the checksum structure. Elastic blog on file formats Tested On Elasticsearch 6.8.12 (single-node, Docker). Renamed to a name of the same length. A new alias was then created for the old name, successfully routing writes to a new index.\n","permalink":"https://blog.mbwarez.dk/posts/2021/renaming-an-index-in-elastic/","summary":"\u003cp\u003eSometimes you need to rename an Elasticsearch index‚Äîmaybe to reuse the name for an alias. Officially, this isn\u0026rsquo;t supported. But with some manual edits and caution, it can be done.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e‚ö†Ô∏è Warning: This is dangerous and unsupported. Back up your data first.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"recommended-alternatives\"\u003eRecommended Alternatives\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html\"\u003eReindex API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html\"\u003eSnapshot and restore\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-split-index.html\"\u003eIndex split\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf these don‚Äôt work for your case, read on.\u003c/p\u003e\n\u003ch2 id=\"the-hacky-method\"\u003eThe Hacky Method\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eStop the Elasticsearch node.\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eFind the metadata files\u003c/strong\u003e:\u003c/p\u003e","title":"Renaming an index in Elastic (slight hacks)"},{"content":"Windows Subsystem for Linux is awesome, but storing its files on the system drive can be limiting. Here‚Äôs how to move WSL distributions to another disk.\nList Containers wsl --list Sample output:\nWindows Subsystem for Linux Distributions: ubuntu (Default) docker-desktop-data docker-desktop Move a Container Shut down WSL to avoid issues: wsl --shutdown Export the container: wsl --export ubuntu N:\\ubuntu.tar Unregister the container: wsl --unregister ubuntu Re-import to new location: wsl --import ubuntu N:\\WSL\\ubuntu N:\\ubuntu.tar --version 2 (Optional) Delete the exported .tar file after verifying the setup. This approach preserves the distro while allowing full control over its storage location.\n","permalink":"https://blog.mbwarez.dk/posts/2021/move-wsl-to-different-drive/","summary":"\u003cp\u003eWindows Subsystem for Linux is awesome, but storing its files on the system drive can be limiting. Here‚Äôs how to move WSL distributions to another disk.\u003c/p\u003e\n\u003ch2 id=\"list-containers\"\u003eList Containers\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewsl --list\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSample output:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eWindows Subsystem for Linux Distributions:\nubuntu (Default)\ndocker-desktop-data\ndocker-desktop\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"move-a-container\"\u003eMove a Container\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eShut down WSL to avoid issues:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewsl --shutdown\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003col start=\"2\"\u003e\n\u003cli\u003eExport the container:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewsl --export ubuntu N:\u003cspan class=\"se\"\u003e\\u\u003c/span\u003ebuntu.tar\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003col start=\"3\"\u003e\n\u003cli\u003eUnregister the container:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewsl --unregister ubuntu\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003col start=\"4\"\u003e\n\u003cli\u003eRe-import to new location:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ewsl --import ubuntu N:\u003cspan class=\"se\"\u003e\\W\u003c/span\u003eSL\u003cspan class=\"se\"\u003e\\u\u003c/span\u003ebuntu N:\u003cspan class=\"se\"\u003e\\u\u003c/span\u003ebuntu.tar --version \u003cspan class=\"m\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003col start=\"5\"\u003e\n\u003cli\u003e(Optional) Delete the exported \u003ccode\u003e.tar\u003c/code\u003e file after verifying the setup.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis approach preserves the distro while allowing full control over its storage location.\u003c/p\u003e","title":"Move WSL to different drive"},{"content":"For reference, here is a SandCastle-produced help file for Sandbox.Common from Space Engineers 01.172.\nüëâ Download Documentation.chm\nInteresting Starting Points Sandbox.ModAPI.IMyGridProgram ‚Äî All in-game scripts inherit from this interface. This documentation is especially useful when writing programmable block scripts for automation and custom logic in-game.\n","permalink":"https://blog.mbwarez.dk/posts/2017/space-engineers-01-172-api-documentation/","summary":"\u003cp\u003eFor reference, here is a SandCastle-produced help file for \u003ccode\u003eSandbox.Common\u003c/code\u003e from \u003cstrong\u003eSpace Engineers 01.172\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eüëâ \u003ca href=\"/posts/2017/space-engineers-01-172-api-documentation/Documentation.chm\"\u003eDownload Documentation.chm\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"interesting-starting-points\"\u003eInteresting Starting Points\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eSandbox.ModAPI.IMyGridProgram\u003c/code\u003e ‚Äî All in-game scripts inherit from this interface.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis documentation is especially useful when writing programmable block scripts for automation and custom logic in-game.\u003c/p\u003e","title":"Space Engineers 01.172 - API Documentation"},{"content":"This is a short note on how we can develop scripts for use in the game Space Engineers.\nBackground A friend suggested Space Engineers to me, so I bought it and after some scavenging, mining and dying‚ÄîI tried out the Programmable Block. To my surprise, it used C#!\nThere was one caveat though: the documentation was outdated and often unusable. I managed to piece together scripts using various posts on the official wiki, its Action List, and API List, plus some Reddit threads.\nEventually I realized‚ÄîI could just disassemble the game and inspect it directly.\nDisassembly Using DotPeek from JetBrains (makers of ReSharper), I decompiled the game DLLs from the Steam install directory. This gave me full access to type definitions and method declarations.\nTip: Got an object you don\u0026rsquo;t recognize? Use this trick inside your script to inspect the type:\nthrow new Exception(TheObject.GetType().FullName); Or more safely, output it via:\nEcho(TheObject.GetType().FullName); Example Search Say you‚Äôre working with a door and know the type is IMyDoor. A search in DotPeek reveals two relevant namespaces inside the Sandbox.Common assembly:\nSandbox.ModAPI Sandbox.ModAPI.Ingame Looking closer, Sandbox.ModAPI.IMyDoor inherits from Sandbox.ModAPI.Ingame.IMyDoor. The latter is the one with the useful members like Status, OpenDoor(), etc.\nIn this image, we can see that Open is marked obsolete in favor of Status, but without external documentation, it‚Äôs hard to know how to use Status properly.\nPlacing the cursor on DoorStatus and pressing F12 brings us to its enum definition, clearing up any confusion.\nConclusion Reverse engineering with DotPeek makes Space Engineers scripting much more accessible. Until official documentation catches up, it‚Äôs a fantastic way to explore the API.\n","permalink":"https://blog.mbwarez.dk/posts/2017/space-engineers-figuring-out-the-api/","summary":"\u003cp\u003eThis is a short note on how we can develop scripts for use in the game Space Engineers.\u003c/p\u003e\n\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eA friend suggested \u003ca href=\"http://store.steampowered.com/app/244850/\"\u003eSpace Engineers\u003c/a\u003e to me, so I bought it and after some scavenging, mining and dying‚ÄîI tried out the \u003ca href=\"http://www.spaceengineerswiki.com/Programmable_Block\"\u003eProgrammable Block\u003c/a\u003e. To my surprise, it used C#!\u003c/p\u003e\n\u003cp\u003eThere was one caveat though: the documentation was outdated and often unusable. I managed to piece together scripts using various posts on the \u003ca href=\"http://www.spaceengineerswiki.com/Programming_Guide\"\u003eofficial wiki\u003c/a\u003e, its \u003ca href=\"http://www.spaceengineerswiki.com/Programming_Guide/Action_List\"\u003eAction List\u003c/a\u003e, and \u003ca href=\"http://www.spaceengineerswiki.com/Programming_Guide/API_List\"\u003eAPI List\u003c/a\u003e, plus some Reddit threads.\u003c/p\u003e","title":"Space Engineers, figuring out the API"},{"content":"Sometimes we\u0026rsquo;re presented objects in JSON that do not directly map to a strongly typed object. Here‚Äôs a simple example:\n[ { \u0026#34;type\u0026#34;: \u0026#34;Car\u0026#34;, \u0026#34;wheels\u0026#34;: 4, \u0026#34;trunk\u0026#34;: true }, { \u0026#34;type\u0026#34;: \u0026#34;Bicycle\u0026#34;, \u0026#34;wheels\u0026#34;: 2, \u0026#34;persons\u0026#34;: 1 } ] The goal is to deserialize these into their respective types, Car and Bicycle, both inheriting from a shared base class Vehicle.\nJsonConverter JsonConverter allows you to customize how JSON is deserialized. Here\u0026rsquo;s an implementation that checks the type property and instantiates the appropriate object:\npublic class VehicleConverter : JsonConverter { public override object ReadJson(JsonReader reader, Type objectType, object existingValue, JsonSerializer serializer) { JToken jObject = JToken.ReadFrom(reader); VehicleType type = jObject[\u0026#34;type\u0026#34;].ToObject\u0026lt;VehicleType\u0026gt;(); Vehicle result = type switch { VehicleType.Car =\u0026gt; new Car(), VehicleType.Bicycle =\u0026gt; new Bicycle(), _ =\u0026gt; throw new ArgumentOutOfRangeException() }; serializer.Populate(jObject.CreateReader(), result); return result; } // WriteJson and CanConvert omitted } Note: We use Populate() instead of Deserialize() to avoid recursion, which would trigger our converter again and cause a stack overflow. Newtonsoft.Json will detect this and throw a JsonSerializationException with a \u0026ldquo;self referencing loop\u0026rdquo; message.\nFlexibility This method is flexible:\nYou can auto-discover applicable types from assemblies. You could use a registration system to associate types. Serialization Caveat The example above registers the converter directly on the Vehicle type. This makes serialization problematic, since the same converter would be called again. One workaround is to register the converter via JsonSerializerSettings instead. This allows you to restrict its use to deserialization only by configuring CanConvert() accordingly.\nExample Code The full code is available here: github.com/LordMike/blog-examples/deserialize-different-types\n[1] Newtonsoft.Json avoids stack overflow by throwing a JsonSerializationException about self-referencing loops.\n","permalink":"https://blog.mbwarez.dk/posts/2016/deserializing-different-types-based-on-properties-with-newtonsoft-json/","summary":"\u003cp\u003eSometimes we\u0026rsquo;re presented objects in JSON that do not directly map to a strongly typed object. Here‚Äôs a simple example:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Car\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;wheels\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;trunk\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Bicycle\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;wheels\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;persons\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe goal is to deserialize these into their respective types, \u003ccode\u003eCar\u003c/code\u003e and \u003ccode\u003eBicycle\u003c/code\u003e, both inheriting from a shared base class \u003ccode\u003eVehicle\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"jsonconverter\"\u003eJsonConverter\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eJsonConverter\u003c/code\u003e allows you to customize how JSON is deserialized. Here\u0026rsquo;s an implementation that checks the \u003ccode\u003etype\u003c/code\u003e property and instantiates the appropriate object:\u003c/p\u003e","title":"Deserializing different types based on properties, with Newtonsoft.Json"},{"content":"A common issue in API client libraries is mismatches between the JSON response and the expected strongly typed objects. I encountered this with TMDbLib and created a validator to catch these mismatches during unit testing.\nThe Settings We can set up a JsonSerializerSettings object to:\nTreat missing properties as errors. Use a custom ContractResolver to enforce that all expected properties must exist in the JSON. Handle and log deserialization errors without throwing immediately. private static readonly List\u0026lt;ErrorEventArgs\u0026gt; Errors = new List\u0026lt;ErrorEventArgs\u0026gt;(); public static void Main() { JsonSerializerSettings settings = new JsonSerializerSettings { MissingMemberHandling = MissingMemberHandling.Error, ContractResolver = new FailingContractResolver(), Error = Error }; JsonSerializer serializer = JsonSerializer.Create(settings); } private static void Error(object sender, ErrorEventArgs errorEventArgs) { Errors.Add(errorEventArgs); errorEventArgs.ErrorContext.Handled = true; } This configuration makes sure that:\nMissing members in JSON trigger errors. All expected C# properties must appear in the JSON unless explicitly marked ignored. Errors are collected rather than thrown, allowing full diagnostics. Custom ContractResolver The contract resolver ensures every C# property must appear in the JSON unless marked with [JsonIgnore]:\npublic class FailingContractResolver : DefaultContractResolver { protected override JsonProperty CreateProperty(MemberInfo member, MemberSerialization memberSerialization) { JsonProperty res = base.CreateProperty(member, memberSerialization); if (!res.Ignored) res.Required = Required.AllowNull; // Make properties required unless ignored return res; } } Using It Once configured, the custom serializer can be used to Deserialize any object. If the JSON is missing properties or includes unexpected ones, they will be logged via the Error handler.\nThis technique is great for catching subtle mismatches during unit testing.\nExample Code You can find the code used in this post here: github.com/LordMike/blog-examples/detect-mismatched-objects-newtonsoft\nSeeing It in Action This validation setup is used in the TMDbLib test suite:\nTestBase.cs FailingContractResolver.cs Each test inherits from TestBase, which configures the validator and throws errors at teardown if mismatches were detected. Some exceptions can be suppressed where needed.\n","permalink":"https://blog.mbwarez.dk/posts/2016/detecting-mismatched-objects-with-newtonsoft-json/","summary":"\u003cp\u003eA common issue in API client libraries is mismatches between the JSON response and the expected strongly typed objects. I encountered this with \u003ca href=\"https://github.com/LordMike/TMDbLib\"\u003eTMDbLib\u003c/a\u003e and created a validator to catch these mismatches during unit testing.\u003c/p\u003e\n\u003ch2 id=\"the-settings\"\u003eThe Settings\u003c/h2\u003e\n\u003cp\u003eWe can set up a \u003ccode\u003eJsonSerializerSettings\u003c/code\u003e object to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTreat missing properties as errors.\u003c/li\u003e\n\u003cli\u003eUse a custom \u003ccode\u003eContractResolver\u003c/code\u003e to enforce that all expected properties must exist in the JSON.\u003c/li\u003e\n\u003cli\u003eHandle and log deserialization errors without throwing immediately.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-csharp\" data-lang=\"csharp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003ereadonly\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eErrorEventArgs\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eErrors\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eErrorEventArgs\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e \u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"n\"\u003eMain\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eJsonSerializerSettings\u003c/span\u003e \u003cspan class=\"n\"\u003esettings\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eJsonSerializerSettings\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eMissingMemberHandling\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eMissingMemberHandling\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eError\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eContractResolver\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eFailingContractResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eError\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eError\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eJsonSerializer\u003c/span\u003e \u003cspan class=\"n\"\u003eserializer\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eJsonSerializer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esettings\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"n\"\u003eError\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eobject\u003c/span\u003e \u003cspan class=\"n\"\u003esender\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eErrorEventArgs\u003c/span\u003e \u003cspan class=\"n\"\u003eerrorEventArgs\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eErrors\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eerrorEventArgs\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eerrorEventArgs\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eErrorContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHandled\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis configuration makes sure that:\u003c/p\u003e","title":"Detecting mismatched objects with Newtonsoft.Json"},{"content":"This is a short post on using Let‚Äôs Encrypt to get TLS certificates for NGINX virtual hosts. The setup assumes:\nUbuntu NGINX hosting multiple domains A scheduler (e.g., cron or Rundeck) Let‚Äôs Encrypt Let‚Äôs Encrypt offers free domain-validated (DV) certificates for HTTPS and other secure services.\nletsencrypt.org GitHub Initial Setup I run multiple web services on VMs behind a single public IP. My NGINX proxy manages SSL termination and routing using virtual host configs.\nGoals:\nQuickly add new sites/domains Let the proxy manage SSL termination Handle renewals automatically Use config snippets for reusable sections Configuring NGINX Install the letsencrypt package, which provides the /usr/bin/letsencrypt binary.\nCreate the challenge snippet at /etc/nginx/snippets/letsencrypt.conf:\nlocation \u0026#39;/.well-known/acme-challenge\u0026#39; { default_type \u0026#34;text/plain\u0026#34;; root /tmp/letsencrypt-auto; } Include it in relevant server blocks:\ninclude /etc/nginx/snippets/letsencrypt.conf; Creating a New Site For a new domain (e.g. letsencrypt.mbwarez.dk), create its config at: /etc/nginx/sites-enabled/letsencrypt.mbwarez.dk\nserver { listen 80; server_name letsencrypt.mbwarez.dk; # SSL config (commented out until certs exist) #ssl_certificate /etc/letsencrypt/live/letsencrypt.mbwarez.dk/fullchain.pem; #ssl_certificate_key /etc/letsencrypt/live/letsencrypt.mbwarez.dk/privkey.pem; include /etc/nginx/snippets/letsencrypt.conf; include /etc/nginx/snippets/hpkp-sts.conf; root /var/www/letsencrypt.mbwarez.dk; } Now run:\n/usr/bin/letsencrypt certonly --text --non-interactive --keep \\ --email certificate-admin@mbwarez.dk \\ --webroot --webroot-path=/tmp/letsencrypt-auto \\ -d letsencrypt.mbwarez.dk Let‚Äôs Encrypt will verify the domain by fetching a file under /.well-known/acme-challenge. If successful, the certificate will be saved in: /etc/letsencrypt/live/letsencrypt.mbwarez.dk/\nNow uncomment the SSL lines in your config and restart NGINX:\nserver { listen 80; listen 443 ssl; server_name letsencrypt.mbwarez.dk; ssl_certificate /etc/letsencrypt/live/letsencrypt.mbwarez.dk/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/letsencrypt.mbwarez.dk/privkey.pem; include /etc/nginx/snippets/letsencrypt.conf; include /etc/nginx/snippets/hpkp-sts.conf; root /var/www/letsencrypt.mbwarez.dk; } Renewal Script Let‚Äôs Encrypt certificates expire every 90 days. Here\u0026rsquo;s a script I run weekly (via cron) to renew all certs:\n#!/bin/bash DIR=/tmp/letsencrypt-auto TOOL=/usr/bin/letsencrypt mkdir -p $DIR function updatecert() { DOMAIN=$1 echo \u0026#34;UPDATING cert for $DOMAIN\u0026#34; $TOOL certonly --text --non-interactive --keep \\ --email certificate-admin@mbwarez.dk \\ --webroot --webroot-path=$DIR \\ -d $DOMAIN } updatecert blog.mbwarez.dk updatecert cygwin.mbwarez.dk updatecert letsencrypt.mbwarez.dk updatecert mbwarez.dk updatecert plex.mbwarez.dk updatecert scm.mbwarez.dk echo \u0026#34;RESTARTING nginx\u0026#34; service nginx configtest \u0026amp;\u0026amp; service nginx reload exit $? Final Thoughts Adding new domains is simple‚Äîjust include them in this script and restart NGINX. Certificates are automatically renewed, and the proxy config stays clean and modular.\nSecure, scriptable, and scalable.\n","permalink":"https://blog.mbwarez.dk/posts/2016/lets-encrypt-organized-for-reverse-nginx-proxy/","summary":"\u003cp\u003eThis is a short post on using Let‚Äôs Encrypt to get TLS certificates for NGINX virtual hosts. The setup assumes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUbuntu\u003c/li\u003e\n\u003cli\u003eNGINX hosting multiple domains\u003c/li\u003e\n\u003cli\u003eA scheduler (e.g., cron or Rundeck)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"lets-encrypt\"\u003eLet‚Äôs Encrypt\u003c/h2\u003e\n\u003cp\u003eLet‚Äôs Encrypt offers free domain-validated (DV) certificates for HTTPS and other secure services.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://letsencrypt.org/\"\u003eletsencrypt.org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/letsencrypt\"\u003eGitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"initial-setup\"\u003eInitial Setup\u003c/h2\u003e\n\u003cp\u003eI run multiple web services on VMs behind a single public IP. My NGINX proxy manages SSL termination and routing using virtual host configs.\u003c/p\u003e","title":"Lets Encrypt organized for reverse nginx proxy"},{"content":"Previously, I described a Bencoding Library I made to simplify working with the Bencoding structure in .NET. I also published it on Codeplex. However, I discovered a flaw‚Äîif a string contains a null-byte (as most .torrent files do), it will fail. So I made a fix, which has been uploaded to Codeplex as changeset 1102.\nAs can be seen in the changeset, a few files have been changed. Ignoring all the test files, the changes were made to:\nBase.cs Bencode.String.cs And that‚Äôs pretty much it. However, these changes are significant. The differences can be seen here:\nDiff for Base.cs Diff for Bencode.String.cs The changes mainly involve treating strings as byte arrays, with helper conversions between string and byte array. The Decode() function has been overridden and now provides two methods: one using strings (as before) and another using a BinaryReader, which allows for reading strings containing null bytes.\nAnd that‚Äôs it. :P\n","permalink":"https://blog.mbwarez.dk/posts/2010/bencoding-library-party-two/","summary":"\u003cp\u003e\u003ca href=\"/posts/2010/bencoding-library/\"\u003ePreviously\u003c/a\u003e, I described a Bencoding Library I made to simplify working with the Bencoding structure in .NET. I also published it on \u003ca href=\"http://bencode.codeplex.com/\"\u003eCodeplex\u003c/a\u003e. However, I discovered a flaw‚Äîif a string contains a null-byte (as most \u003ccode\u003e.torrent\u003c/code\u003e files do), it will fail. So I made a fix, which has been uploaded to Codeplex as \u003ca href=\"http://bencode.codeplex.com/SourceControl/changeset/changes/1102\"\u003echangeset 1102\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAs can be seen in the changeset, a few files have been changed. Ignoring all the test files, the changes were made to:\u003c/p\u003e","title":"Bencoding Library‚ÄìPart two"},{"content":"I asked around while trying to learn how to use LINQ. LINQ is essentially SQL for .NET‚Äîit allows you to query objects directly in memory. For example:\nList\u0026lt;int\u0026gt; test = new List\u0026lt;int\u0026gt; { 1, 3, 5 }; List\u0026lt;int\u0026gt; testnew = (from a in test where a == 5 select a).ToList(); Someone claimed LINQ was faster than using foreach for selecting items. So, I tested it.\nThe Benchmark static List\u0026lt;int\u0026gt; testlist = new List\u0026lt;int\u0026gt;(); static void Main(string[] args) { DateTime b, a; List\u0026lt;double\u0026gt; regularTimes = new List\u0026lt;double\u0026gt;(); List\u0026lt;double\u0026gt; LINQTimes = new List\u0026lt;double\u0026gt;(); for (int x = 0; x \u0026lt; 1000000; x++) testlist.Add(x * 5); // Foreach loop test for (int x = 0; x \u0026lt; 1000; x++) { b = DateTime.Now; TestRegular(); a = DateTime.Now; regularTimes.Add((a - b).TotalMilliseconds); } Console.WriteLine(\u0026#34;Regular Avg.: {0}\u0026#34;, regularTimes.Average()); // LINQ test for (int x = 0; x \u0026lt; 1000; x++) { b = DateTime.Now; TestLINQ(); a = DateTime.Now; LINQTimes.Add((a - b).TotalMilliseconds); } Console.WriteLine(\u0026#34;LINQ Avg.: {0}\u0026#34;, LINQTimes.Average()); Console.ReadLine(); } private static void TestRegular() { List\u0026lt;int\u0026gt; newlist = new List\u0026lt;int\u0026gt;(); foreach (int item in testlist) if (item % 2000 == 0) newlist.Add(item); } private static void TestLINQ() { var newlist = (from a in testlist where a % 2000 == 0 select a).ToList(); } This runs each selection method 1000 times on a list of 1,000,000 items.\nResults Regular Avg.: 81.64 ms LINQ Avg.: 84.31 ms Conclusion The difference is negligible and could be attributed to background system noise. Based on this test, LINQ and regular iteration perform similarly.\nUse whichever fits your coding style and needs.\n","permalink":"https://blog.mbwarez.dk/posts/2010/linq-vs-foreach/","summary":"\u003cp\u003eI asked around while trying to learn how to use LINQ. LINQ is essentially SQL for .NET‚Äîit allows you to query objects directly in memory. For example:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-csharp\" data-lang=\"csharp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"m\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"m\"\u003e5\u003c/span\u003e \u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003etestnew\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003efrom\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e \u003cspan class=\"k\"\u003ewhere\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e==\u003c/span\u003e \u003cspan class=\"m\"\u003e5\u003c/span\u003e \u003cspan class=\"k\"\u003eselect\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eToList\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSomeone claimed LINQ was faster than using \u003ccode\u003eforeach\u003c/code\u003e for selecting items. So, I tested it.\u003c/p\u003e\n\u003ch3 id=\"the-benchmark\"\u003eThe Benchmark\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-csharp\" data-lang=\"csharp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003etestlist\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"n\"\u003eMain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eDateTime\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003edouble\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eregularTimes\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003edouble\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003edouble\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eLINQTimes\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003edouble\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"m\"\u003e1000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e++)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003etestlist\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e*\u003c/span\u003e \u003cspan class=\"m\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// Foreach loop test\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"m\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e++)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eb\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDateTime\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNow\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eTestRegular\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDateTime\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNow\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eregularTimes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdd\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eTotalMilliseconds\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Regular Avg.: {0}\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eregularTimes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAverage\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// LINQ test\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"m\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e++)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eb\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDateTime\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNow\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eTestLINQ\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDateTime\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNow\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eLINQTimes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdd\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eTotalMilliseconds\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;LINQ    Avg.: {0}\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eLINQTimes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAverage\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eReadLine\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"n\"\u003eTestRegular\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003enewlist\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eforeach\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003etestlist\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"p\"\u003e%\u003c/span\u003e \u003cspan class=\"m\"\u003e2000\u003c/span\u003e \u003cspan class=\"p\"\u003e==\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003enewlist\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAdd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003estatic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"n\"\u003eTestLINQ\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003enewlist\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003efrom\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003etestlist\u003c/span\u003e \u003cspan class=\"k\"\u003ewhere\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e \u003cspan class=\"p\"\u003e%\u003c/span\u003e \u003cspan class=\"m\"\u003e2000\u003c/span\u003e \u003cspan class=\"p\"\u003e==\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e \u003cspan class=\"k\"\u003eselect\u003c/span\u003e \u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eToList\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis runs each selection method 1000 times on a list of 1,000,000 items.\u003c/p\u003e","title":"LINQ vs. Foreach"},{"content":"An Introduction So, I‚Äôm moving into an apartment in the near future. Following that, I will have to learn how to manage my documents and ensure I can find them back in time. I‚Äôve thought of a few solutions, one of them being what I do now ‚Äì where I simply have a folder with PDFs of my documents (I digitalize everything). This works fine now\u0026hellip; (I have like ‚Ä¶ 20 documents)\u0026hellip; But it may not work in 2 years when I have a hundred documents spread over many different corporations and years.\nI then thought of making the system searchable. This means I need a method of indexing all documents, preferably long-term. I thought of making a website, where I attach metadata to each uploaded document (that I make searchable by using OCR). Metadata will include things like the start and end date, a descriptive title, and perhaps one or two categories.\nThe idea is to archive all documents and bills from cable, ISP, heating, electricity, etc., with their validity dates. When I search for a given date, I want to see all documents that cover that date and match those criteria (for example, ‚ÄúElectricity‚Äù).\nUsing a system like this, it‚Äôd be easy to go back in time and view bills from a provider at a given date‚Äîwithout pulling down a 4 KG Ring Binder full of mixed pages.\nBackground Tools I, of course, would want to code this in C#, preferably as a web application. I‚Äôll need a method to extract text from PDF documents (headings, tables, regular text) for indexing purposes.\nFor reading PDFs in C#, I found this blog post about PDFBox. It‚Äôs originally a Java library but can be used in C#. After testing, I found that PDFBox doesn‚Äôt handle most of my OCR-scanned PDFs.\nA Stack Overflow article confirmed this problem. The first post recommends PDFTextStream, which works well but isn‚Äôt free.\nBack to square one, I found PdfToText, a simple command-line tool available here. It outputs exactly what I need‚Äîfor free!\nThe plan is to use this utility in the application. It exports a text file that the app can read.\nThe Database The database is an important part. I plan to have tables for:\nUsers: Security is important. Documents: The core of the product. Categories: To assist with sorting. Initially, I won‚Äôt store files in the DB‚Äîjust text for search. I‚Äôll store filename, hash (SHA1), upload date, and the extracted text. The hash maps to the physical file.\nEach document also gets a date range (datefrom, dateto). If dateto is empty, only datefrom is relevant.\nThe Website I‚Äôll code the site in C#. This time, I‚Äôm using LINQ. It allows direct queries on my database in code (not using ADO.Net). Really handy for fast development.\nI‚Äôm also using .ashx handlers to provide downloads without exposing file locations. This lets me use the app_data folder securely.\nKey features:\nPDF extraction Private security considerations Document encryption Searching algorithm Download page PDF Extraction I settled on Xpdf for extracting text.\nprivate void PDFToText(string tempName, out string error, out string text) { string path_exe = Server.MapPath(\u0026#34;~/app_data/temp/pdftotext.exe\u0026#34;); string path_pdf = Server.MapPath(\u0026#34;~/app_data/temp/\u0026#34; + tempName); string path_txt = Server.MapPath(\u0026#34;~/app_data/temp/\u0026#34; + tempName + \u0026#34;.txt\u0026#34;); var pstart = new System.Diagnostics.ProcessStartInfo { FileName = path_exe, Arguments = $\u0026#34;\\\u0026#34;{path_pdf}\\\u0026#34; \\\u0026#34;{path_txt}\\\u0026#34;\u0026#34;, UseShellExecute = false, RedirectStandardOutput = false, RedirectStandardError = true, CreateNoWindow = true }; var p = new System.Diagnostics.Process { StartInfo = pstart }; p.Start(); p.WaitForExit(); text = File.Exists(path_txt) ? File.ReadAllText(path_txt) : \u0026#34;\u0026#34;; if (File.Exists(path_txt)) File.Delete(path_txt); error = p.StandardError.ReadToEnd(); } Considerations of Private Security Some files contain personal data (e.g., Danish CPR numbers). I created a regex to remove patterns like xxxxxx-xxxx, replacing them with {CPR REMOVED}.\nEncryption of Documents I encrypt uploaded files using the user‚Äôs password and TripleDES, using this wrapper.\nIf a user changes their password, all documents are re-encrypted. A dencrypthash field tracks which password was used. Not the most secure system‚Äîmore ‚Äúsecurity by obscurity‚Äù‚Äîbut sufficient for my use.\nSearching Algorithm This is my proudest part. I used to build huge SQL queries. With LINQ, I build object-based filters.\nI:\nFilter by categories (inclusion/exclusion) Filter by date ranges Extract full-text content Use splitters to tokenize text Search by name/content/tags using different matching methods (Begins With, Ends With, AND, OR) Despite being a bit slow (¬Ω‚Äì1s per search), it‚Äôs flexible and understandable.\nDownload Page I use .ashx handlers to control downloads securely. The app_data folder is perfect since IIS blocks direct access.\nHandlers check session login and document ownership. Then they decrypt the file if necessary and stream it back to the user.\nConclusion This project taught me a lot about LINQ, secure file storage with app_data, and practical encryption. I now have a working document archive system that I use personally.\nThe site is live with 23 MB of PDFs and growing.\nI‚Äôm as happy with this as I was with Mobifinance. The DocsArchive site was previously available here (link may be broken).\n","permalink":"https://blog.mbwarez.dk/posts/2010/pdf-search-site/","summary":"\u003ch1 id=\"an-introduction\"\u003eAn Introduction\u003c/h1\u003e\n\u003cp\u003eSo, I‚Äôm moving into an apartment in the near future. Following that, I will have to learn how to manage my documents and ensure I can find them back in time. I‚Äôve thought of a few solutions, one of them being what I do now ‚Äì where I simply have a folder with PDFs of my documents (I digitalize everything). This works fine now\u0026hellip; (I have like ‚Ä¶ 20 documents)\u0026hellip; But it may not work in 2 years when I have a hundred documents spread over many different corporations and years.\u003c/p\u003e","title":"PDF Search Site"},{"content":"I‚Äôve long wanted to write a Bencoding library. Bencoding is an encoding format for encoding objects like text, lists, dictionaries, etc., into a single piece of text. It‚Äôs often used for transporting configuration files.\nBencoding is most famous for its use in the Bittorrent protocol‚Äîit forms the basis for .torrent files. I wanted to create a C# library to support all known Bencoding object types. You can read more about the encoding here.\nAs a bonus, I also tried out the Team Foundation Server on Codeplex while coding the project.\nThe Objects There are four Bencode object types:\nByte strings ‚Äì e.g., \u0026quot;Hello World\u0026quot; Integers ‚Äì e.g., 1, 42, -999 Lists ‚Äì ordered elements like (\u0026quot;hello\u0026quot;, 42) Dictionaries ‚Äì key/value mappings, e.g., { \u0026quot;Hello\u0026quot; =\u0026gt; \u0026quot;Mike\u0026quot; } Each object has a specific format:\nString: 5:Hello (5-byte string) Integer: i42e List: l5:helloi42ee (list of ‚Äúhello‚Äù and 42) Nested List: l5:Hellol12:second level16:second string :Pee Dictionary: d5:Hello4:Mikee Lexicographical dictionary: d1:ai52e1:b8:Object 1e The next task was designing classes to support these structures.\nThe Class Layout To maintain good OOP practices, I created a base type that all Bencode types derive from. This allowed lists and dictionaries to store base-type objects. The base is abstract, requiring child classes to override methods.\nEncoding Each object overrides a virtual Encode() method, allowing recursive encoding across nested structures.\nDecoding I added a static Decode() method in the base type to parse a string recursively, decoding one object at a time.\nError Handling To handle malformed inputs, I defined these exceptions:\nExcept_Error ‚Äì generic errors Except_Error_String Except_Error_Int Except_Error_Dict Except_Error_List All inherit from Except_Error and expose the failing string segment.\nThe Code The code is available at Codeplex source. Click ‚ÄúBrowse‚Äù to see the latest revision. Look for the BencodeLibrary project.\nNotable files:\nBase.cs ‚Äì the base type Bencode.Dict.cs ‚Äì dictionary handling Operator Overloads I implemented overloads for ==, !=, and Equals() to compare values meaningfully:\npublic static bool operator ==(BString first, BString second) =\u0026gt; first.Value == second.Value; public static bool operator !=(BString first, BString second) =\u0026gt; first.Value != second.Value; public override bool Equals(object obj) { if (obj == null || GetType() != obj.GetType()) return false; return this == (BString)obj; } For lists:\npublic static bool operator ==(BList first, BList second) { if (first.Value.Count != second.Value.Count) return false; for (int x = 0; x \u0026lt; first.Value.Count; x++) { if (!Equals(first.Value[x], second.Value[x])) return false; } return true; } Encode Each object implements its Encode() method:\nInteger: public override string Encode() =\u0026gt; $\u0026#34;i{_data.ToString(BaseType.GlobalizationCultureInfo)}e\u0026#34;; String: public override string Encode() =\u0026gt; $\u0026#34;{_data.Length}:{_data}\u0026#34;; List: public override string Encode() { var res = new StringBuilder(\u0026#34;l\u0026#34;); foreach (var item in _childs) res.Append(item.Encode()); res.Append(\u0026#34;e\u0026#34;); return res.ToString(); } Dictionary: public override string Encode() { var res = new StringBuilder(\u0026#34;d\u0026#34;); foreach (var item in _childs.OrderBy(kv =\u0026gt; kv.Key.Value)) { res.Append(item.Key.Encode()); res.Append(item.Value.Encode()); } res.Append(\u0026#34;e\u0026#34;); return res.ToString(); } This supports recursive encoding of complex structures.\nDecode The Decode(ref string Input) method checks the first character of the string and parses accordingly:\n'i' for integers 'l' for lists 'd' for dictionaries digits for strings Each branch recursively decodes any child objects. Errors are caught and rethrown as specific exceptions with context.\nThe Result I now have a fully functional library to encode and decode Bencoded strings. It‚Äôs object-oriented and comes with Visual Studio unit tests.\nThe code is hosted on TFS via Codeplex. The project is in Alpha, and I‚Äôm watching for feedback in the discussion forums.\n","permalink":"https://blog.mbwarez.dk/posts/2010/bencoding-library/","summary":"\u003cp\u003eI‚Äôve long wanted to write a \u003ca href=\"http://en.wikipedia.org/wiki/Bencode\"\u003eBencoding\u003c/a\u003e library. Bencoding is an encoding format for encoding objects like text, lists, dictionaries, etc., into a single piece of text. It‚Äôs often used for transporting configuration files.\u003c/p\u003e\n\u003cp\u003eBencoding is most famous for its use in the Bittorrent protocol‚Äîit forms the basis for \u003ccode\u003e.torrent\u003c/code\u003e files. I wanted to create a C# library to support all known Bencoding object types. You can read \u003ca href=\"http://wiki.theory.org/BitTorrentSpecification#bencoding\"\u003emore about the encoding here\u003c/a\u003e.\u003c/p\u003e","title":"Bencoding ‚Äì A C# Library"},{"content":"Introduction For my previous post, where I find the signal strength of WiFi spots, I also needed an algorithm to actually locate the spot. I decided to use triangulation, which is commonly used in wireless communications to locate devices based on signal strength from known positions.\nAs my system uses GPS, I had to consider the Earth\u0026rsquo;s curvature. Calculating the geographic midpoint on a sphere isn\u0026rsquo;t trivial, but GeoMidpoint provides a great explanation (Method A).\nMethod Overview Convert every geographic coordinate into a 3D Cartesian coordinate. Then apply weights, compute a weighted average, and convert back to geographic coordinates using atan2 and Pythagorean calculations.\nDetailed Method Convert lat/lon to X, Y, Z:\nx = cos(lat) * cos(lon) y = cos(lat) * sin(lon) z = sin(lat) Set the weight: If not supplied, default to 1.\nSum total weight: wht_total = w1 + w2 + ... + wn\nCompute weighted average:\nx_avg = (x1*w1 + x2*w2 + ... + xn*wn) / wht_total y_avg = (y1*w1 + y2*w2 + ... + yn*wn) / wht_total z_avg = (z1*w1 + z2*w2 + ... + zn*wn) / wht_total Convert back to lat/lon:\nlon = atan2(y_avg, x_avg) lat = atan2(z_avg, sqrt(x_avg¬≤ + y_avg¬≤)) Code (C#) Coordinate Classes class GeoCoordinate { public double Longitude { get; set; } public double Latitude { get; set; } public GeoCoordinate() { Longitude = 0; Latitude = 0; } public GeoCoordinate(double lat, double lon) { Longitude = lon; Latitude = lat; } } class GeoCoordinate_Weighted : GeoCoordinate { public double Weight { get; set; } = 1; public GeoCoordinate_Weighted(double lat, double lon, double weight) { Longitude = lon; Latitude = lat; Weight = weight; } } class Coordinate3D { public double X, Y, Z; public Coordinate3D() { X = Y = Z = 0; } public Coordinate3D(double x, double y, double z) { X = x; Y = y; Z = z; } } Weighted Midpoint Calculation static GeoCoordinate CalculateCentre(List\u0026lt;GeoCoordinate_Weighted\u0026gt; input) { double totalWeight = 0; Coordinate3D sum = new Coordinate3D(); foreach (var point in input) { double latRad = Rad(point.Latitude); double lonRad = Rad(point.Longitude); sum.X += Math.Cos(latRad) * Math.Cos(lonRad) * point.Weight; sum.Y += Math.Cos(latRad) * Math.Sin(lonRad) * point.Weight; sum.Z += Math.Sin(latRad) * point.Weight; totalWeight += point.Weight; } sum.X /= totalWeight; sum.Y /= totalWeight; sum.Z /= totalWeight; double lon = Deg(Math.Atan2(sum.Y, sum.X)); double lat = Deg(Math.Atan2(sum.Z, Math.Sqrt(sum.X * sum.X + sum.Y * sum.Y))); return new GeoCoordinate(lat, lon); } static double Deg(double rad) =\u0026gt; rad * 180 / Math.PI; static double Rad(double deg) =\u0026gt; deg * Math.PI / 180; Test Case Example 1:\nvar list = new List\u0026lt;GeoCoordinate_Weighted\u0026gt; { new GeoCoordinate_Weighted(20, 10, 10), new GeoCoordinate_Weighted(0, 0, 1), new GeoCoordinate_Weighted(-20, -10, 1) }; var centre = CalculateCentre(list); Console.WriteLine($\u0026#34;Latitude: {centre.Latitude}, Longitude: {centre.Longitude}\u0026#34;); Matches GeoMidPoint output:\nLatitude: 15.26935 Longitude: 7.48369 Example 2: 10 random global coordinates also match GeoMidPoint‚Äôs output.\nConclusion The weighted midpoint algorithm works as expected. My application accurately matches GeoMidPoint‚Äôs output. Great for future triangulation-based location work!\n","permalink":"https://blog.mbwarez.dk/posts/2010/wardriving-triangulation/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eFor my \u003ca href=\"/posts/2010/wifi-scanner/\"\u003eprevious post\u003c/a\u003e, where I find the signal strength of WiFi spots, I also needed an algorithm to actually locate the spot. I decided to use triangulation, which is commonly used in wireless communications to locate devices based on signal strength from known positions.\u003c/p\u003e\n\u003cp\u003eAs my system uses GPS, I had to consider the Earth\u0026rsquo;s curvature. Calculating the geographic midpoint on a sphere isn\u0026rsquo;t trivial, but \u003ca href=\"http://www.geomidpoint.com/calculation.html\"\u003eGeoMidpoint\u003c/a\u003e provides a great explanation (Method A).\u003c/p\u003e","title":"Wardriving ‚Äì The triangulation algorithm"},{"content":"Introduction I‚Äôve long wanted to build a WiFi-based application‚Äîideally one that also records GPS location data for wardriving. I searched for manageable C# solutions integrated with .NET.\nFirst Attempts I explored many WMI tutorials, but on Windows 7, I lacked the needed namespaces like MSNdis_80211_ServiceSetIdentifier.\nEventually, I discovered the WLan API (available since Windows XP SP3), usable via P/Invoke. Fortunately, someone made a ManagedWifi wrapper for it‚Äîperfect!\nThe Scanner I wrote a small utility that scans for SSIDs across all interfaces and retrieves their MAC addresses.\nThe code was based on help from a Stack Overflow thread and enhanced with info on BSSID access.\nCode Snippet static void Main(string[] args) { WlanClient client = new WlanClient(); foreach (WlanClient.WlanInterface wlanIface in client.Interfaces) { Wlan.WlanBssEntry[] wlanBssEntries = wlanIface.GetNetworkBssList(); foreach (Wlan.WlanBssEntry network in wlanBssEntries) { byte[] macAddr = network.dot11Bssid; string tMac = string.Join(\u0026#34;:\u0026#34;, macAddr.Select(b =\u0026gt; b.ToString(\u0026#34;x2\u0026#34;)).ToArray()).ToUpper(); Console.WriteLine(\u0026#34;Found network with SSID {0}.\u0026#34;, GetStringForSSID(network.dot11Ssid)); Console.WriteLine(\u0026#34;Signal: {0}%.\u0026#34;, network.linkQuality); Console.WriteLine(\u0026#34;BSS Type: {0}.\u0026#34;, network.dot11BssType); Console.WriteLine(\u0026#34;MAC: {0}.\u0026#34;, tMac); Console.WriteLine(); } } Console.ReadLine(); } static string GetStringForSSID(Wlan.Dot11Ssid ssid) { return Encoding.ASCII.GetString(ssid.SSID, 0, (int)ssid.SSIDLength); } Conclusion With just a few lines and the ManagedWifi wrapper, I now have a solid base for my wardriving app‚Äîincluding signal strength, MAC address, and SSID collection. GPS integration and location storage will be next.\nMore to come!\n","permalink":"https://blog.mbwarez.dk/posts/2010/wifi-scanner/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eI‚Äôve long wanted to build a WiFi-based application‚Äîideally one that also records GPS location data for wardriving. I searched for manageable C# solutions integrated with .NET.\u003c/p\u003e\n\u003ch3 id=\"first-attempts\"\u003eFirst Attempts\u003c/h3\u003e\n\u003cp\u003eI explored many \u003ca href=\"http://en.wikipedia.org/wiki/Windows_Management_Instrumentation#Wireless_networking_example\"\u003eWMI tutorials\u003c/a\u003e, but on Windows 7, I lacked the needed namespaces like \u003ccode\u003eMSNdis_80211_ServiceSetIdentifier\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eEventually, I discovered the WLan API (available since Windows XP SP3), usable via P/Invoke. Fortunately, someone made a \u003ca href=\"http://managedwifi.codeplex.com/\"\u003eManagedWifi\u003c/a\u003e wrapper for it‚Äîperfect!\u003c/p\u003e\n\u003ch2 id=\"the-scanner\"\u003eThe Scanner\u003c/h2\u003e\n\u003cp\u003eI wrote a small utility that scans for SSIDs across all interfaces and retrieves their MAC addresses.\u003c/p\u003e","title":"C# Wifi Scanner"},{"content":"I was reading several articles about the new NemID system in Denmark, and concerns around how organized groups might generate valid CPR numbers and brute-force passwords. This could lead to account lockouts‚Äîpotentially paralyzing major parts of the country‚Äôs digital infrastructure.\nTo test this, I created code to generate valid CPR numbers based on known rules.\nThe Rules The original rules were based on a textbook I no longer have, but I found newer ones via this blog post, official article, and PDF document from the CPR register.\nNote: My code uses the old rules (pre-2007) because I couldn‚Äôt verify new CPR numbers.\nSummary of Rules 10 digits long First 6 digits are the birthdate: DDMMYY format Must be a valid date 7th digit indicates the century: Even centuries: digit 5‚Äì9 Odd centuries: digit 0‚Äì4 Digits 8‚Äì9 are arbitrary 10th digit determines sex: Even = female, Odd = male A modulus test is used: Each digit is multiplied by a predefined factor (4,3,2,7,6,5,4,3,2,1). If the total sum mod 11 is 0, the CPR is valid.\nThe Code CPR Check I tested three versions of a modulus check:\nstatic bool CheckCPR(int[] Input) { int[] factors = { 4, 3, 2, 7, 6, 5, 4, 3, 2, 1 }; int sum = 0; for (int x = 0; x \u0026lt; factors.Length; x++) sum += Input[x] * factors[x]; return sum % 11 == 0; } Int arrays performed slightly better than byte arrays or strings.\nCPR Generator ‚Äì Date Generation Two methods were compared:\nUsing DateTime (valid dates only) Using nested loops (all combinations) DateTime was slower (~70ms vs. ~5ms) but avoids invalid dates. I chose this method for accuracy.\nstatic int[][] GenerateDates_DateObject() { DateTime tDate = new DateTime(1900, 1, 1); DateTime tMax = new DateTime(2010, 1, 1); var results = new List\u0026lt;int[]\u0026gt;(); while (tDate \u0026lt; tMax) { tDate = tDate.AddDays(1); var day = tDate.Day.ToString(\u0026#34;D2\u0026#34;); var month = tDate.Month.ToString(\u0026#34;D2\u0026#34;); var year = tDate.Year; results.Add(new int[] { int.Parse(day[0].ToString()), int.Parse(day[1].ToString()), int.Parse(month[0].ToString()), int.Parse(month[1].ToString()), year }); } return results.ToArray(); } Control Digit Generator static int[] ControlDigits(int[] InputDate) { var result = new List\u0026lt;int\u0026gt;(); int[] valids = (InputDate[4] / 100) % 2 == 0 ? new[] { 5, 6, 7, 8, 9 } : new[] { 0, 1, 2, 3, 4 }; foreach (int x in valids) for (int y = 0; y \u0026lt;= 999; y++) result.Add(int.Parse($\u0026#34;{x}{y:D3}\u0026#34;)); return result.ToArray(); } Takes ~7ms to generate 5000 possibilities.\nFinal CPR Generator static void Main() { using var writer = new StreamWriter(\u0026#34;output.txt\u0026#34;); var dates = GenerateDates_DateObject(); foreach (var date in dates) { var controlCodes = ControlDigits(date); foreach (var code in controlCodes) { var year = date[4].ToString().Substring(2); var control = code.ToString(\u0026#34;D4\u0026#34;); int[] cpr = { date[0], date[1], date[2], date[3], int.Parse(year[0].ToString()), int.Parse(year[1].ToString()), int.Parse(control[0].ToString()), int.Parse(control[1].ToString()), int.Parse(control[2].ToString()), int.Parse(control[3].ToString()) }; if (CheckCPR(cpr)) writer.WriteLine(string.Join(\u0026#34;\u0026#34;, cpr)); } } } The Result After ~19.5 minutes, I generated a 219 MB file with 18,262,698 valid CPR numbers from 1900 to 2010.\nThis list can be used for analysis, e.g., estimating valid CPRs per day/year.\nAnd yes‚Äîmy own CPR number is valid! üòÑ\n","permalink":"https://blog.mbwarez.dk/posts/2010/cpr-numbers/","summary":"\u003cp\u003eI was reading several articles about the new NemID system in Denmark, and concerns around how organized groups might \u003ca href=\"http://www.version2.dk/artikel/15708-danid-ja-det-er-muligt-at-spaerre-andres-nemid\"\u003egenerate valid CPR numbers\u003c/a\u003e and brute-force passwords. This could lead to account lockouts‚Äîpotentially paralyzing major parts of the country‚Äôs digital infrastructure.\u003c/p\u003e\n\u003cp\u003eTo test this, I created code to generate valid CPR numbers based on known rules.\u003c/p\u003e\n\u003ch2 id=\"the-rules\"\u003eThe Rules\u003c/h2\u003e\n\u003cp\u003eThe original rules were based on a textbook I no longer have, but I found newer ones via this \u003ca href=\"http://blog.splitpoint.dk/?p=129\"\u003eblog post\u003c/a\u003e, \u003ca href=\"http://www.cpr.dk/cpr/site.aspx?p=108\u0026amp;t=visartikel\u0026amp;Articleid=4347\"\u003eofficial article\u003c/a\u003e, and \u003ca href=\"http://www.cpr.dk/cpr_artikler/Files/Fil1/4229.pdf\"\u003ePDF document\u003c/a\u003e from the CPR register.\u003c/p\u003e","title":"Danish CPR Numbers"},{"content":"Idea While on a trip to Jutland, I had a splendid idea: a system to track loans‚Äîwho I loaned money to and whether I ever got it back. It had to work on mobile devices and as a web app, so I built it as a small webpage.\nI used an MSSQL database (hosted by addnet.dk) and wrote the app in C#.\nDatabase I built a single main table, Finances, for all loans and edits. Each finance can have a parent‚ÄîNULL indicates a root loan. This allows loan tracking and later edits. A root loan of +10 DKK, followed by a -10 DKK update, resolves to 0 (paid).\nLoans can be updated multiple times in either direction. The Finances table is tied to two other tables:\nAccounts: multiple accounts for organizing finances Contacts: people who borrow or lend Every finance is tied to one contact and one account.\nTo make loan status checks faster, I created a column that stores the current value of a root loan (sum of all children). A scalar function in MSSQL 2005 keeps it up to date:\nCREATE FUNCTION [dbo].[GetFinancesNewValueByID] (@fid int) RETURNS decimal(20, 2) AS BEGIN DECLARE @result decimal(20, 2) SELECT @result = SUM(fvalue) FROM dbo.finances WHERE (fid = @fid) OR (faffect = @fid) RETURN @result END Similar functions exist for accounts and contacts. That way, I always fetch pre-calculated results instead of computing on the fly.\nSite The frontend is minimal‚Äîblack and white, except for loan values:\nRed: Negative Green: Positive Black: Zero or neutral Once a user account is set up, you can create contacts and accounts. These are essential for assigning and tracking loans.\nI also implemented a way to move loans: combining smaller, independent loans into one. This was handy for situations like shopping for parents, then settling up at the end of the month.\nResult The final site is live at mobifinance.mbwarez.dk (link may be broken). It\u0026rsquo;s free for anyone to use. Although emails are collected, they\u0026rsquo;re not used (originally meant for signup/forgot password flows).\nI‚Äôve used the site daily since around June 4th, 2009. It‚Äôs stable and meets my needs. Most bugs were ironed out early on.\n","permalink":"https://blog.mbwarez.dk/posts/2010/mobifinance-loaning-organized/","summary":"\u003ch2 id=\"idea\"\u003eIdea\u003c/h2\u003e\n\u003cp\u003eWhile on a trip to Jutland, I had a splendid idea: a system to track loans‚Äîwho I loaned money to and whether I ever got it back. It had to work on mobile devices and as a web app, so I built it as a small webpage.\u003c/p\u003e\n\u003cp\u003eI used an MSSQL database (hosted by \u003ca href=\"http://addnet.dk\"\u003eaddnet.dk\u003c/a\u003e) and wrote the app in C#.\u003c/p\u003e\n\u003ch2 id=\"database\"\u003eDatabase\u003c/h2\u003e\n\u003cp\u003eI built a single main table, \u003ccode\u003eFinances\u003c/code\u003e, for all loans and edits. Each finance can have a parent‚Äî\u003ccode\u003eNULL\u003c/code\u003e indicates a root loan. This allows loan tracking and later edits. A root loan of +10 DKK, followed by a -10 DKK update, resolves to 0 (paid).\u003c/p\u003e","title":"Mobifinance ‚Äì Loaning organized"},{"content":"Introduction While reviewing my old college\u0026rsquo;s IT class backup system (due to running low on disk space), I discovered a major flaw: a weekly 1:1 backup of every user\u0026rsquo;s files‚Äîabout 40 GB per week. Many of these files never change. Ever.\nSolution: Incremental backups.\nI challenged myself to code an incremental backup system using only Python and the Linux extfs filesystem.\nThe Scenario At my former college, students ran the IT department. They set up a system with a 2 TB drive (two 1 TB disks) that made weekly full backups of every user, including alumni.\nIt was neat‚Äîusers could browse weekly snapshots through subdomains like week35.rtgkom.dk. For instance:\nMy site: http://rtgkom.dk/~michaelgb07/ My news feed: index.php?menu=0\u0026amp;sub=1 Week 1 copy: Week01 Problem: Disk usage ballooned due to full 1:1 weekly backups. I needed a transparent, filesystem-only solution (no DBs, no viewers).\nTheories I discovered hardlinking, which links multiple filenames to the same disk block. It means multiple folders can share the same file without duplicating space.\nIdea: Backup each unique file once. Hardlink all future identical files to the original. Use SHA1 hashes to identify file uniqueness. Example: If 100 users install WordPress (9 MB each), that‚Äôs 900 MB total. With hardlinking, we can store just 9 MB + config/plugin deltas.\nA ‚Äúdata‚Äù folder holds unique files named by SHA1. Backup folders hardlink to these.\nThe Script Written in Python using the built-in optparse.\nCommand: python backupsystem.py --help Options: --rootfolder=ROOTFOLDER Source directory to mirror from --backupfolder=BACKUPFOLDER Destination snapshot folder --datafolder=DATAFOLDER Directory for unique hash-named files --datalevels=N Subdirectory levels inside datafolder (default: 0) --createdirs Assume yes to all directory creation prompts --pauseonerror Pause on errors --awaituserinput Wait for user input before backup starts --folderspause Wait before processing folders --filespause Wait before processing files --dostats Show stats at end (requires -v) --doprogress=N Show progress every N files (requires -v) --ignorefileexists Ignore \u0026#34;file exists\u0026#34; errors --hash=HASHMETHOD Hash method (e.g., sha1) -v Verbose output (repeat for more detail) Example: sudo python backupsystem.py --rootfolder=/files/ --backupfolder=/backup/week10/ --datafolder=/backup/data This creates week10 (snapshot) and data (unique content) in /backup/.\nUse --createdirs to suppress folder creation prompts.\nFilecount Consideration To avoid sluggish file managers (e.g., Windows Explorer), use --datalevels=N to create subfolders:\nWith --datalevels=3, file AABBCCDDEEFF is stored as:\n/backup/data/AA/BB/CC/AABBCCDDEEFF This spreads files across multiple directories.\nUsage Keep some parameters consistent (datafolder, datalevels). Changing them resets the system.\nOnly the backupfolder changes between runs‚Äîit represents a snapshot.\nNote: Editing any file in a snapshot affects all linked copies!\nAdvantages \u0026amp; Considerations Pros: Saves space through deduplication and hardlinking. Transparent snapshots without special viewers. Cons: Centralized data increases corruption risk (RAID suggested). Editing one file alters all linked instances. Script Download Script available for educational use: Download Backupsystem.py\nThis system was designed as a simple, transparent backup solution that leverages hardlinking and hashing for efficient storage.\n","permalink":"https://blog.mbwarez.dk/posts/2010/incremental-file-backup/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhile reviewing my old college\u0026rsquo;s IT class backup system (due to running low on disk space), I discovered a major flaw: a weekly 1:1 backup of every user\u0026rsquo;s files‚Äîabout 40 GB per week. Many of these files never change. Ever.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e Incremental backups.\u003c/p\u003e\n\u003cp\u003eI challenged myself to code an incremental backup system using only Python and the Linux extfs filesystem.\u003c/p\u003e\n\u003ch2 id=\"the-scenario\"\u003eThe Scenario\u003c/h2\u003e\n\u003cp\u003eAt my former college, students ran the IT department. They set up a system with a 2 TB drive (two 1 TB disks) that made weekly full backups of every user, including alumni.\u003c/p\u003e","title":"Linux incremental hardlink backup system"},{"content":"Introduction As part of the OEP platform at my previous college, we designed an SMS subsystem for messaging Danish mobile phones. It was intended for alerts like account lockouts or password resets. I coded it in Python.\nThe Scenario We used LDAP as a central user database. The script needed to accept either a phone number or username, then look up the mobile number via LDAP (mobile attribute). I used python-ldap for this, available via Ubuntu\u0026rsquo;s package system.\nThere were two usage modes:\nWithout a database (direct send) With a database queue (MySQL), to delay non-urgent messages I wrote the SMS send script as a module to be reused by the database-driven queue script.\nThe System There are three parts:\nSMS Sender: Sends messages via HTTPS SMS Insert: Adds a message to the database SMS Database: Cronjob script that checks and sends queued messages LDAP Integration The common library used in other RTGKom.dk scripts provided the getMember(userid) function. From there, we could get the mobile number:\ndef GetNumber(value): try: return int(value) except: pass cl = commonLibrary() user = cl.getMember(value) return int(user[\u0026#39;mobile\u0026#39;]) if \u0026#39;mobile\u0026#39; in user else 0 SMS Send Script We used CPSms.dk as a gateway. Their API PDF helped build the HTTPS requests.\nI used optparse to parse command-line arguments. The script builds a query URL and sends it if SMS_ACTIVE = True. Here‚Äôs a snippet:\nif SMS_ACTIVE: response = urlopen(SMS_SERVER + url).read() else: response = \u0026#34;\u0026lt;error\u0026gt;SMS_ACTIVE: False\u0026lt;/error\u0026gt;\u0026#34; SMS Insert Script This script inserts a message into the MySQL todo table:\nsql = \u0026#34;\u0026#34;\u0026#34; INSERT INTO `todo` (`sfrom`, `srecipient`, `smessage`, `spriority`, `sstatus`, `sdate`) VALUES (%s, %s, %s, %s, \u0026#39;todo\u0026#39;, CURRENT_TIMESTAMP); \u0026#34;\u0026#34;\u0026#34; It also supports a --highpriority flag to bypass timing rules.\nSMS Database Script This script is meant to run periodically (e.g., every minute via cron). It handles timing rules like:\nSMS_MAXPRDAY = 10 SMS_HOURLOW = 7 SMS_HOURHIGH = 22 It sends queued messages only within defined hours, unless marked high priority.\nResult The system worked reliably‚Äîminus a bug related to nonexistent users (fixed). With or without the MySQL layer, it‚Äôs flexible and free to use.\nLDAP integration makes it suitable for organizations, but the system can run independently as well.\nAll in all: success. ‚úÖ\n","permalink":"https://blog.mbwarez.dk/posts/2010/sms-system/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAs part of the OEP platform at my previous college, we designed an SMS subsystem for messaging Danish mobile phones. It was intended for alerts like account lockouts or password resets. I coded it in Python.\u003c/p\u003e\n\u003ch2 id=\"the-scenario\"\u003eThe Scenario\u003c/h2\u003e\n\u003cp\u003eWe used LDAP as a central user database. The script needed to accept either a phone number or username, then look up the mobile number via LDAP (\u003ccode\u003emobile\u003c/code\u003e attribute). I used \u003ca href=\"http://www.python-ldap.org/\"\u003epython-ldap\u003c/a\u003e for this, available via Ubuntu\u0026rsquo;s package system.\u003c/p\u003e","title":"SMS System"}]